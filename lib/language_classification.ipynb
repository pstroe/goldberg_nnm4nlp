{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification - Language Classification\n",
    "\n",
    "This notebook implements the method presented in Goldberg's [2017] book \"Neural Network Methods for Natural Language Processing\". It shows the steps you need to go through in order to successfully train a classifier, and it should also, so I hope, illustrate the notational differences between Goldberg and standard machine learning literature.\n",
    "\n",
    "$NOTE$: There is no cross-validation etc. to find optimal parameters. This is simply to show how multi-class classification works. This will be part of a tutorial session and all other concepts will be explained there.\n",
    "\n",
    "Author: Phillip Ströbel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and cleaning the data\n",
    "\n",
    "The data consists of downloaded Wikipedia articles (see `urls.txt`) in German, English, French, Spanish, Italian and Finnish (instead of \"O\" in Goldberg). The data is in HTML, so we need to some preprocessing to get the text out of it. We also restrict ourselfes to the characters from a to z in the alphabet (as described in Goldberg). In this fashion, we get rid of all the Umlauts (ä, ö, ü) and all other characters with diacritics (as, e.g., the é or ç in French). Note however, that if these characters ocurring in bigrams would probably be good features. In some way, we still keep the information \"special character\" by not fully deleting the character, but by replacing it by the dollar sign \"\\$\". Furthermore, we replace all punctuation marks and digits by dollar signs as well. As such, all special characters, digits, and punctuation marks are mapped to $. The space will be replaced by an underscore \"\\_\". We then represent each langauge by 28 characters, as is suggested by Goldberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning HTML\n",
    "We first strip the HTML to get only the text of the Wikipedia page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from collections import defaultdict\n",
    "\n",
    "seed = np.random.seed(seed=200)  # set a seed for random, so results are reproducible\n",
    "\n",
    "article_dict = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "regex = r'[\\n ]{2,}'\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "urls = open('urls.txt', 'r').readlines()\n",
    "\n",
    "for index, url in enumerate(urls):\n",
    "    language = url[8:10]\n",
    "    doc_id = 'doc_%d' % index\n",
    "    html = urlopen(url.strip()).read()    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    raw = soup.body.get_text()  # only get text from the text body (this excludes headers and should exclude navigation bars)\n",
    "    raw = re.sub(pattern, ' ', raw)  # replace multiple breaks and spaces by only one space\n",
    "    raw = re.sub(r'\\n', ' ', raw)  # replace every line break with a space\n",
    "    article_dict[language][doc_id] = raw.lower()  # assign each text to its language and lower all uppercase characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing --> prepare the text\n",
    "replace special characters and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dict = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "abc = r'[a-z]'\n",
    "abc_pattern = re.compile(abc)\n",
    "\n",
    "for lang, doc in article_dict.items():\n",
    "    for doc, text in doc.items():\n",
    "        for char in text:\n",
    "            if re.match(abc_pattern, char):\n",
    "                preprocessed_dict[lang][doc] += char\n",
    "            elif re.match(' ', char):\n",
    "                preprocessed_dict[lang][doc] += '_'\n",
    "            else:\n",
    "                preprocessed_dict[lang][doc] += '$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count bigrams --> Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of bigrams will be our only feature. We could extend this by taking into account other n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = 'abcdefghijklmnopqrstuvwxyz$_'  # define the character set we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement, permutations\n",
    "\n",
    "def bigrams(text):\n",
    "    \"\"\"\n",
    "    Function to extract bigrams from text and calculate their distribution\n",
    "    :param text: text string\n",
    "    :return: dictionary containing bigrams as keys, and the normalised count as values\n",
    "    \"\"\"\n",
    "    combs = combinations_with_replacement(charset, 2)\n",
    "    perms = permutations(charset, 2)\n",
    "    bigram_dict = dict()\n",
    "    \n",
    "    for comb in set(list(combs) + list(perms)):\n",
    "        bigram_dict[''.join(comb)] = 0\n",
    "        \n",
    "    doc_length = len(text)\n",
    "    \n",
    "    for index in range(0, len(text)-1):\n",
    "        bigram = text[index] + text[index+1]\n",
    "        bigram_dict[bigram] += 1\n",
    "                \n",
    "    for bigram, count in bigram_dict.items():\n",
    "        bigram_dict[bigram] = count/doc_length\n",
    "\n",
    "    return bigram_dict              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put data into pandas dataframe\n",
    "The pandas dataframe allows us to conveniently represent all the data we need in one table. So let's do this. But first we need to extract the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dict_full = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for lang, doc in preprocessed_dict.items():\n",
    "    for doc, text in sorted(doc.items()):\n",
    "        bigram_dict = bigrams(text)\n",
    "        bigram_dict_full[lang][doc] = bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$</th>\n",
       "      <th>$_</th>\n",
       "      <th>$a</th>\n",
       "      <th>$b</th>\n",
       "      <th>$c</th>\n",
       "      <th>$d</th>\n",
       "      <th>$e</th>\n",
       "      <th>$f</th>\n",
       "      <th>$g</th>\n",
       "      <th>$h</th>\n",
       "      <th>...</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100732</td>\n",
       "      <td>0.036889</td>\n",
       "      <td>0.000292</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062182</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072008</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075458</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064235</td>\n",
       "      <td>0.032112</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         $$        $_        $a        $b        $c        $d        $e  \\\n",
       "0  0.100732  0.036889  0.000292  0.000222  0.000332  0.000163  0.000239   \n",
       "1  0.062182  0.028909  0.000513  0.000322  0.000520  0.000356  0.000629   \n",
       "2  0.072008  0.031248  0.000444  0.000519  0.000497  0.000187  0.000340   \n",
       "3  0.075458  0.035249  0.000400  0.000466  0.000453  0.000268  0.000303   \n",
       "4  0.064235  0.032112  0.000344  0.000301  0.000735  0.000295  0.000476   \n",
       "\n",
       "         $f        $g        $h    ...           zq        zr        zs   zt  \\\n",
       "0  0.000181  0.000099  0.000152    ...     0.000000  0.000006  0.000006  0.0   \n",
       "1  0.000192  0.000185  0.000171    ...     0.000007  0.000007  0.000000  0.0   \n",
       "2  0.000246  0.000093  0.000179    ...     0.000000  0.000004  0.000000  0.0   \n",
       "3  0.000224  0.000312  0.000189    ...     0.000000  0.000004  0.000000  0.0   \n",
       "4  0.000313  0.000271  0.000187    ...     0.000000  0.000000  0.000006  0.0   \n",
       "\n",
       "         zu        zv        zw   zx        zy        zz  \n",
       "0  0.000023  0.000000  0.000000  0.0  0.000000  0.000006  \n",
       "1  0.000027  0.000000  0.000000  0.0  0.000014  0.000021  \n",
       "2  0.000030  0.000004  0.000004  0.0  0.000011  0.000000  \n",
       "3  0.000013  0.000000  0.000000  0.0  0.000009  0.000000  \n",
       "4  0.000006  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = ['y'] + sorted(bigram_dict_full['en']['doc_0'].keys())\n",
    "my_df = dict()\n",
    "\n",
    "for col in col_names:\n",
    "    my_df[col] = list()\n",
    "    \n",
    "df = pd.DataFrame(my_df)\n",
    "\n",
    "for lang, doc in bigram_dict_full.items():\n",
    "    for key, value in doc.items():\n",
    "        df_obj = value\n",
    "        df_obj['y'] = lang\n",
    "        df = df.append(df_obj, ignore_index=True)\n",
    "        \n",
    "df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 785)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into the label vector \\begin{equation}\\mathbf{y}\\end{equation} and a training data matrix \\begin{equation}\\mathbf{X}\\end{equation}. But first, we shuffle the df and split it into a training and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, it is necessary for many machine learning tasks to standardise the data. Our aim is for each feature to be represented by a column vector in which values have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_point(datapoint, mean, std):\n",
    "    \"\"\"\n",
    "    normalise a datapoint to zero mean and unit variance.\n",
    "    :param datapoint: value as a float\n",
    "    :param mean: mean of data vector x\n",
    "    :param std: standard deviation of data vector x\n",
    "    :return: normalised datapoint (float)\n",
    "    \"\"\"\n",
    "    return (datapoint - mean)/std\n",
    "\n",
    "def normalise_matrix(matrix):\n",
    "    \"\"\"\n",
    "    normalises the data matrix\n",
    "    :param matrix: input matrix\n",
    "    :return: normalised matrix\n",
    "    \"\"\"\n",
    "    train_normalised = matrix.copy()\n",
    "    \n",
    "    for col in matrix:\n",
    "        try:\n",
    "            mean = matrix[col].mean()\n",
    "            std = matrix[col].std()\n",
    "            for index, item in enumerate(matrix[col]):\n",
    "                train_normalised.loc[index, col] = normalise_point(item, mean, std)\n",
    "        except ZeroDivisionError:\n",
    "            train_normalised.loc[index, col] = 0.0\n",
    "        except TypeError:\n",
    "            continue\n",
    "    return train_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = normalise_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a train set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_norm.sample(frac=0.9, random_state=seed)\n",
    "test = df_norm.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training\n",
    "y_train = train.y\n",
    "X_train = train.drop('y', axis=1)\n",
    "\n",
    "# for testing\n",
    "y_test = test.y\n",
    "X_test = test.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples shape:  (54, 784)\n",
      "Training labels shape:  (54,)\n",
      "Test samples shape:  (6, 784)\n",
      "Test labels shape:  (6,)\n"
     ]
    }
   ],
   "source": [
    "print('Training samples shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test samples shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should binarise our labels, although libraries like sklearn can also deal with non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(['en', 'fr', 'de', 'it', 'es', 'fi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', 'en', 'es', 'fi', 'fr', 'it'], dtype='<U2')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this for both our training and test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = lb.transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are now one-hot encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We almost have everything now. However, we need to take care of the bias and the weight matrix. The hypothesis ŷ is given by:\n",
    "\\begin{equation}\n",
    "\\mathbf{\\hat{y}}=\\mathbf{x}\\cdot\\mathbf{W}+\\mathbf{b}\n",
    "\\end{equation}\n",
    "We can achieve this by appending 1 to each feature vector x, and the whole weight vector b to the weight matrix W. This is called the bias trick. Note that the dimensions of X_train change, and that the weight matrix W will have match the dimensions (same number of rows as X has columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$</th>\n",
       "      <th>$_</th>\n",
       "      <th>$a</th>\n",
       "      <th>$b</th>\n",
       "      <th>$c</th>\n",
       "      <th>$d</th>\n",
       "      <th>$e</th>\n",
       "      <th>$f</th>\n",
       "      <th>$g</th>\n",
       "      <th>$h</th>\n",
       "      <th>...</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.416705</td>\n",
       "      <td>0.724450</td>\n",
       "      <td>0.415587</td>\n",
       "      <td>-0.679809</td>\n",
       "      <td>-0.973339</td>\n",
       "      <td>-0.650477</td>\n",
       "      <td>-0.396736</td>\n",
       "      <td>-0.943586</td>\n",
       "      <td>-0.864334</td>\n",
       "      <td>0.838599</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.440930</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.120987</td>\n",
       "      <td>0.754591</td>\n",
       "      <td>-0.134707</td>\n",
       "      <td>-0.331671</td>\n",
       "      <td>-0.658595</td>\n",
       "      <td>-0.085424</td>\n",
       "      <td>-0.824043</td>\n",
       "      <td>-0.596442</td>\n",
       "      <td>-0.633121</td>\n",
       "      <td>-0.322912</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.335276</td>\n",
       "      <td>-0.443910</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.247255</td>\n",
       "      <td>-0.426881</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.325057</td>\n",
       "      <td>-0.583721</td>\n",
       "      <td>-1.236540</td>\n",
       "      <td>1.883605</td>\n",
       "      <td>-0.211154</td>\n",
       "      <td>-0.116536</td>\n",
       "      <td>-0.431807</td>\n",
       "      <td>-0.030221</td>\n",
       "      <td>0.358247</td>\n",
       "      <td>0.851821</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710846</td>\n",
       "      <td>1.222124</td>\n",
       "      <td>2.205323</td>\n",
       "      <td>2.651505</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>2.055032</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.646854</td>\n",
       "      <td>-0.332487</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1.079415</td>\n",
       "      <td>0.965113</td>\n",
       "      <td>0.604424</td>\n",
       "      <td>-0.772101</td>\n",
       "      <td>-0.413109</td>\n",
       "      <td>-0.474101</td>\n",
       "      <td>-0.162789</td>\n",
       "      <td>-0.937614</td>\n",
       "      <td>-0.877095</td>\n",
       "      <td>-1.127295</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.453582</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>1.417154</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-1.162065</td>\n",
       "      <td>-1.478148</td>\n",
       "      <td>1.661925</td>\n",
       "      <td>-0.693171</td>\n",
       "      <td>0.422842</td>\n",
       "      <td>-0.342607</td>\n",
       "      <td>-0.757701</td>\n",
       "      <td>4.229579</td>\n",
       "      <td>1.266662</td>\n",
       "      <td>-1.002757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.412311</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.480037</td>\n",
       "      <td>-0.068256</td>\n",
       "      <td>-1.016916</td>\n",
       "      <td>-0.317620</td>\n",
       "      <td>-0.651997</td>\n",
       "      <td>-0.889553</td>\n",
       "      <td>-0.865333</td>\n",
       "      <td>-0.604453</td>\n",
       "      <td>-0.916012</td>\n",
       "      <td>-0.876075</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089174</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.433836</td>\n",
       "      <td>0.414885</td>\n",
       "      <td>-0.404149</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.052242</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.419297</td>\n",
       "      <td>-0.628931</td>\n",
       "      <td>-0.256807</td>\n",
       "      <td>0.941286</td>\n",
       "      <td>-0.465767</td>\n",
       "      <td>0.939080</td>\n",
       "      <td>-0.617309</td>\n",
       "      <td>0.122219</td>\n",
       "      <td>0.616054</td>\n",
       "      <td>1.578355</td>\n",
       "      <td>...</td>\n",
       "      <td>2.391500</td>\n",
       "      <td>0.508242</td>\n",
       "      <td>1.455085</td>\n",
       "      <td>2.812389</td>\n",
       "      <td>1.970446</td>\n",
       "      <td>1.933324</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>1.260723</td>\n",
       "      <td>-0.405529</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.084960</td>\n",
       "      <td>-0.116761</td>\n",
       "      <td>0.369967</td>\n",
       "      <td>-0.562680</td>\n",
       "      <td>0.821571</td>\n",
       "      <td>-0.558429</td>\n",
       "      <td>0.326681</td>\n",
       "      <td>-0.429021</td>\n",
       "      <td>0.237262</td>\n",
       "      <td>-0.814364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>0.051763</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.450289</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.375646</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.869830</td>\n",
       "      <td>1.050150</td>\n",
       "      <td>0.771172</td>\n",
       "      <td>-0.119695</td>\n",
       "      <td>-0.119732</td>\n",
       "      <td>0.866934</td>\n",
       "      <td>-0.415106</td>\n",
       "      <td>-0.356439</td>\n",
       "      <td>-0.508251</td>\n",
       "      <td>-0.346814</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986253</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.438480</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.003370</td>\n",
       "      <td>1.251760</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.584746</td>\n",
       "      <td>-0.008377</td>\n",
       "      <td>-0.342159</td>\n",
       "      <td>-0.745939</td>\n",
       "      <td>-0.604093</td>\n",
       "      <td>-0.743701</td>\n",
       "      <td>-0.442223</td>\n",
       "      <td>-0.326390</td>\n",
       "      <td>-0.867180</td>\n",
       "      <td>-1.005471</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.463310</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>2.072618</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>4.001936</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.160355</td>\n",
       "      <td>-0.510266</td>\n",
       "      <td>1.069360</td>\n",
       "      <td>0.388705</td>\n",
       "      <td>1.337425</td>\n",
       "      <td>-0.555707</td>\n",
       "      <td>0.504631</td>\n",
       "      <td>0.817953</td>\n",
       "      <td>-0.460466</td>\n",
       "      <td>-0.896099</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.296683</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.606974</td>\n",
       "      <td>-0.786994</td>\n",
       "      <td>-0.789039</td>\n",
       "      <td>1.411476</td>\n",
       "      <td>0.110125</td>\n",
       "      <td>0.859175</td>\n",
       "      <td>-0.563183</td>\n",
       "      <td>0.452142</td>\n",
       "      <td>0.291963</td>\n",
       "      <td>1.255654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.305967</td>\n",
       "      <td>1.831528</td>\n",
       "      <td>3.905810</td>\n",
       "      <td>2.717431</td>\n",
       "      <td>1.021407</td>\n",
       "      <td>4.723271</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.293051</td>\n",
       "      <td>-0.384671</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.731054</td>\n",
       "      <td>-1.069340</td>\n",
       "      <td>-0.771071</td>\n",
       "      <td>0.946844</td>\n",
       "      <td>-0.165820</td>\n",
       "      <td>1.358570</td>\n",
       "      <td>0.175429</td>\n",
       "      <td>0.288854</td>\n",
       "      <td>0.608740</td>\n",
       "      <td>3.325257</td>\n",
       "      <td>...</td>\n",
       "      <td>1.708032</td>\n",
       "      <td>1.046023</td>\n",
       "      <td>1.279115</td>\n",
       "      <td>1.747921</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>1.940661</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>2.829616</td>\n",
       "      <td>-0.237247</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.374990</td>\n",
       "      <td>0.792318</td>\n",
       "      <td>-0.885106</td>\n",
       "      <td>-0.101886</td>\n",
       "      <td>-0.338209</td>\n",
       "      <td>-0.562383</td>\n",
       "      <td>-0.732698</td>\n",
       "      <td>2.285417</td>\n",
       "      <td>-0.509801</td>\n",
       "      <td>-0.707804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.365729</td>\n",
       "      <td>1.137507</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>1.633112</td>\n",
       "      <td>-0.179494</td>\n",
       "      <td>-0.422805</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.470628</td>\n",
       "      <td>0.406582</td>\n",
       "      <td>0.773502</td>\n",
       "      <td>-0.494451</td>\n",
       "      <td>0.047334</td>\n",
       "      <td>-0.479151</td>\n",
       "      <td>-0.112049</td>\n",
       "      <td>0.778703</td>\n",
       "      <td>-0.410403</td>\n",
       "      <td>-0.742613</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.422484</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.398874</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.129934</td>\n",
       "      <td>-0.432569</td>\n",
       "      <td>-0.906443</td>\n",
       "      <td>2.341984</td>\n",
       "      <td>-0.069292</td>\n",
       "      <td>1.575497</td>\n",
       "      <td>-0.336500</td>\n",
       "      <td>0.797094</td>\n",
       "      <td>0.606261</td>\n",
       "      <td>1.575821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.401112</td>\n",
       "      <td>4.551662</td>\n",
       "      <td>1.461255</td>\n",
       "      <td>1.568301</td>\n",
       "      <td>3.107591</td>\n",
       "      <td>1.668815</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.020030</td>\n",
       "      <td>-0.381943</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.472139</td>\n",
       "      <td>0.479092</td>\n",
       "      <td>-0.955308</td>\n",
       "      <td>1.193546</td>\n",
       "      <td>-0.155042</td>\n",
       "      <td>0.017077</td>\n",
       "      <td>-0.534344</td>\n",
       "      <td>-0.164344</td>\n",
       "      <td>-0.110068</td>\n",
       "      <td>-0.501298</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>1.575566</td>\n",
       "      <td>-0.369437</td>\n",
       "      <td>-0.414230</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.262866</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.388084</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.212555</td>\n",
       "      <td>-0.387974</td>\n",
       "      <td>-1.012315</td>\n",
       "      <td>1.271332</td>\n",
       "      <td>-0.138710</td>\n",
       "      <td>0.496517</td>\n",
       "      <td>-0.560440</td>\n",
       "      <td>0.162659</td>\n",
       "      <td>0.700293</td>\n",
       "      <td>1.399921</td>\n",
       "      <td>...</td>\n",
       "      <td>1.341042</td>\n",
       "      <td>0.147864</td>\n",
       "      <td>2.374791</td>\n",
       "      <td>2.198069</td>\n",
       "      <td>1.164244</td>\n",
       "      <td>0.801246</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.648762</td>\n",
       "      <td>-0.392260</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.242306</td>\n",
       "      <td>-0.033589</td>\n",
       "      <td>-0.869463</td>\n",
       "      <td>-0.779880</td>\n",
       "      <td>-1.070756</td>\n",
       "      <td>-0.594749</td>\n",
       "      <td>-0.658617</td>\n",
       "      <td>-0.825272</td>\n",
       "      <td>-1.081516</td>\n",
       "      <td>1.815494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.463310</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.142593</td>\n",
       "      <td>0.239497</td>\n",
       "      <td>0.939542</td>\n",
       "      <td>1.550714</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>3.125947</td>\n",
       "      <td>1.689082</td>\n",
       "      <td>0.143302</td>\n",
       "      <td>2.819317</td>\n",
       "      <td>0.958173</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.404736</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.362545</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.146294</td>\n",
       "      <td>1.347853</td>\n",
       "      <td>1.810199</td>\n",
       "      <td>-0.025791</td>\n",
       "      <td>2.606243</td>\n",
       "      <td>2.133169</td>\n",
       "      <td>1.098803</td>\n",
       "      <td>2.253571</td>\n",
       "      <td>1.174521</td>\n",
       "      <td>0.033015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750925</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.442301</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.060900</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.702021</td>\n",
       "      <td>-0.344423</td>\n",
       "      <td>-0.597028</td>\n",
       "      <td>-0.646175</td>\n",
       "      <td>-0.335801</td>\n",
       "      <td>-0.608541</td>\n",
       "      <td>-0.343229</td>\n",
       "      <td>-0.259520</td>\n",
       "      <td>-0.810001</td>\n",
       "      <td>-0.919208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.463310</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>1.195835</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.985239</td>\n",
       "      <td>-0.625472</td>\n",
       "      <td>1.241179</td>\n",
       "      <td>-0.734727</td>\n",
       "      <td>1.978202</td>\n",
       "      <td>1.399573</td>\n",
       "      <td>1.333163</td>\n",
       "      <td>0.696259</td>\n",
       "      <td>1.198310</td>\n",
       "      <td>0.442127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.463310</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.191590</td>\n",
       "      <td>-1.922174</td>\n",
       "      <td>-0.985369</td>\n",
       "      <td>2.817426</td>\n",
       "      <td>-0.495248</td>\n",
       "      <td>-0.317058</td>\n",
       "      <td>-0.414898</td>\n",
       "      <td>2.220823</td>\n",
       "      <td>1.316457</td>\n",
       "      <td>0.633571</td>\n",
       "      <td>...</td>\n",
       "      <td>3.624157</td>\n",
       "      <td>2.360747</td>\n",
       "      <td>2.246184</td>\n",
       "      <td>2.818240</td>\n",
       "      <td>6.114676</td>\n",
       "      <td>1.636761</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>1.978827</td>\n",
       "      <td>-0.319574</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.513404</td>\n",
       "      <td>0.666082</td>\n",
       "      <td>-0.711825</td>\n",
       "      <td>-0.948278</td>\n",
       "      <td>-1.079049</td>\n",
       "      <td>-0.186843</td>\n",
       "      <td>-0.582692</td>\n",
       "      <td>-0.646036</td>\n",
       "      <td>-0.989816</td>\n",
       "      <td>0.728812</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>0.580567</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.463310</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.246754</td>\n",
       "      <td>1.116633</td>\n",
       "      <td>1.935833</td>\n",
       "      <td>-0.542458</td>\n",
       "      <td>1.698766</td>\n",
       "      <td>2.109075</td>\n",
       "      <td>1.623126</td>\n",
       "      <td>0.512309</td>\n",
       "      <td>0.970411</td>\n",
       "      <td>-0.168753</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.048453</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.457985</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.431359</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.501211</td>\n",
       "      <td>0.005622</td>\n",
       "      <td>-0.115629</td>\n",
       "      <td>-0.898746</td>\n",
       "      <td>-0.396357</td>\n",
       "      <td>-0.834046</td>\n",
       "      <td>-0.436594</td>\n",
       "      <td>-0.779920</td>\n",
       "      <td>-0.916733</td>\n",
       "      <td>-0.769642</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.152943</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.405468</td>\n",
       "      <td>-0.437977</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.107967</td>\n",
       "      <td>1.311096</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.277582</td>\n",
       "      <td>-1.319759</td>\n",
       "      <td>-1.071337</td>\n",
       "      <td>2.327877</td>\n",
       "      <td>0.992075</td>\n",
       "      <td>0.615572</td>\n",
       "      <td>-0.273714</td>\n",
       "      <td>0.049932</td>\n",
       "      <td>0.552725</td>\n",
       "      <td>1.343236</td>\n",
       "      <td>...</td>\n",
       "      <td>2.558737</td>\n",
       "      <td>1.629723</td>\n",
       "      <td>2.648219</td>\n",
       "      <td>1.626710</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>1.302574</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.454667</td>\n",
       "      <td>-0.353493</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.606565</td>\n",
       "      <td>1.290481</td>\n",
       "      <td>-1.152026</td>\n",
       "      <td>-0.852313</td>\n",
       "      <td>-0.865554</td>\n",
       "      <td>-0.941311</td>\n",
       "      <td>-0.934636</td>\n",
       "      <td>-0.806268</td>\n",
       "      <td>-0.901110</td>\n",
       "      <td>-0.929464</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165751</td>\n",
       "      <td>-0.012193</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.440295</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.429677</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.180774</td>\n",
       "      <td>0.166717</td>\n",
       "      <td>-0.930415</td>\n",
       "      <td>1.196283</td>\n",
       "      <td>-0.832790</td>\n",
       "      <td>-0.435373</td>\n",
       "      <td>-0.519674</td>\n",
       "      <td>-1.078235</td>\n",
       "      <td>-0.948478</td>\n",
       "      <td>0.918459</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.338112</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.374928</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.159575</td>\n",
       "      <td>-1.144586</td>\n",
       "      <td>-0.422678</td>\n",
       "      <td>1.926623</td>\n",
       "      <td>-0.209124</td>\n",
       "      <td>0.397376</td>\n",
       "      <td>-0.501690</td>\n",
       "      <td>-0.675728</td>\n",
       "      <td>1.335503</td>\n",
       "      <td>0.803739</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210715</td>\n",
       "      <td>1.570105</td>\n",
       "      <td>2.034345</td>\n",
       "      <td>2.326904</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>2.067396</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.009728</td>\n",
       "      <td>-0.356259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615341</td>\n",
       "      <td>0.895382</td>\n",
       "      <td>-1.055890</td>\n",
       "      <td>-0.412484</td>\n",
       "      <td>-0.708643</td>\n",
       "      <td>-0.709166</td>\n",
       "      <td>-0.890306</td>\n",
       "      <td>-0.672412</td>\n",
       "      <td>-0.352013</td>\n",
       "      <td>-0.856915</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008394</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.450290</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.137374</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-1.139190</td>\n",
       "      <td>-1.231650</td>\n",
       "      <td>0.131123</td>\n",
       "      <td>-0.947542</td>\n",
       "      <td>-0.956697</td>\n",
       "      <td>-0.970912</td>\n",
       "      <td>-0.531843</td>\n",
       "      <td>-0.958774</td>\n",
       "      <td>-0.673852</td>\n",
       "      <td>-1.059598</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.107883</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.458689</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.282992</td>\n",
       "      <td>3.589403</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-1.252123</td>\n",
       "      <td>-1.503758</td>\n",
       "      <td>1.496069</td>\n",
       "      <td>-0.806269</td>\n",
       "      <td>-0.440554</td>\n",
       "      <td>-0.607843</td>\n",
       "      <td>-0.882973</td>\n",
       "      <td>0.252603</td>\n",
       "      <td>-0.559488</td>\n",
       "      <td>-1.093163</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.069008</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.382004</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.398845</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.740300</td>\n",
       "      <td>-0.226174</td>\n",
       "      <td>-0.032427</td>\n",
       "      <td>-0.799070</td>\n",
       "      <td>-0.938453</td>\n",
       "      <td>-1.135623</td>\n",
       "      <td>0.093709</td>\n",
       "      <td>-0.975817</td>\n",
       "      <td>-1.027051</td>\n",
       "      <td>1.885940</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.438523</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.700545</td>\n",
       "      <td>2.502004</td>\n",
       "      <td>0.690202</td>\n",
       "      <td>-0.316864</td>\n",
       "      <td>0.857295</td>\n",
       "      <td>0.392563</td>\n",
       "      <td>4.007624</td>\n",
       "      <td>2.059005</td>\n",
       "      <td>0.563856</td>\n",
       "      <td>0.594744</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.316873</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>3.862169</td>\n",
       "      <td>0.426871</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.076883</td>\n",
       "      <td>1.156058</td>\n",
       "      <td>-0.274081</td>\n",
       "      <td>-0.741392</td>\n",
       "      <td>-0.671524</td>\n",
       "      <td>-0.509089</td>\n",
       "      <td>-0.566280</td>\n",
       "      <td>-0.636301</td>\n",
       "      <td>-0.207808</td>\n",
       "      <td>-0.985257</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604717</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.435358</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.114505</td>\n",
       "      <td>2.142028</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.794411</td>\n",
       "      <td>-0.442621</td>\n",
       "      <td>2.248198</td>\n",
       "      <td>-0.087580</td>\n",
       "      <td>1.191377</td>\n",
       "      <td>0.305267</td>\n",
       "      <td>1.907021</td>\n",
       "      <td>0.160287</td>\n",
       "      <td>1.268669</td>\n",
       "      <td>-0.308142</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.396585</td>\n",
       "      <td>-0.445700</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.367995</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.414483</td>\n",
       "      <td>-0.441130</td>\n",
       "      <td>-1.126537</td>\n",
       "      <td>-1.003832</td>\n",
       "      <td>-0.762120</td>\n",
       "      <td>-0.290585</td>\n",
       "      <td>-0.280206</td>\n",
       "      <td>0.326144</td>\n",
       "      <td>-1.038571</td>\n",
       "      <td>-0.160662</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.463310</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.193931</td>\n",
       "      <td>1.394737</td>\n",
       "      <td>1.803600</td>\n",
       "      <td>-0.143164</td>\n",
       "      <td>2.904004</td>\n",
       "      <td>2.254667</td>\n",
       "      <td>3.313577</td>\n",
       "      <td>0.261024</td>\n",
       "      <td>2.308845</td>\n",
       "      <td>0.673495</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.450905</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.347494</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.226263</td>\n",
       "      <td>-0.403592</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.126770</td>\n",
       "      <td>0.753430</td>\n",
       "      <td>-0.034772</td>\n",
       "      <td>-0.963992</td>\n",
       "      <td>-0.234989</td>\n",
       "      <td>-0.729437</td>\n",
       "      <td>-0.152599</td>\n",
       "      <td>-1.055524</td>\n",
       "      <td>-0.488943</td>\n",
       "      <td>-0.837192</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.443641</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>1.167534</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-1.058280</td>\n",
       "      <td>-1.814741</td>\n",
       "      <td>1.543265</td>\n",
       "      <td>-0.882687</td>\n",
       "      <td>-0.033399</td>\n",
       "      <td>-0.567005</td>\n",
       "      <td>-0.518076</td>\n",
       "      <td>-0.496828</td>\n",
       "      <td>-0.299632</td>\n",
       "      <td>-1.049458</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.438063</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.222239</td>\n",
       "      <td>1.225948</td>\n",
       "      <td>-1.005696</td>\n",
       "      <td>-0.722501</td>\n",
       "      <td>-0.194068</td>\n",
       "      <td>1.367393</td>\n",
       "      <td>-0.155605</td>\n",
       "      <td>0.343720</td>\n",
       "      <td>-0.063301</td>\n",
       "      <td>-0.528314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.431100</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.295855</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>1.862587</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.353289</td>\n",
       "      <td>0.271504</td>\n",
       "      <td>-0.123417</td>\n",
       "      <td>0.290318</td>\n",
       "      <td>-0.183112</td>\n",
       "      <td>0.305302</td>\n",
       "      <td>-0.241121</td>\n",
       "      <td>-0.363963</td>\n",
       "      <td>-0.621188</td>\n",
       "      <td>-0.720383</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.360791</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.369487</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>1.909708</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.164607</td>\n",
       "      <td>-0.232252</td>\n",
       "      <td>-1.025665</td>\n",
       "      <td>-0.628756</td>\n",
       "      <td>-0.649144</td>\n",
       "      <td>-0.875430</td>\n",
       "      <td>-0.861095</td>\n",
       "      <td>-0.743698</td>\n",
       "      <td>-0.700542</td>\n",
       "      <td>-0.662615</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.455372</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.389980</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094656</td>\n",
       "      <td>-0.631656</td>\n",
       "      <td>-0.956070</td>\n",
       "      <td>-0.672588</td>\n",
       "      <td>-0.621613</td>\n",
       "      <td>-0.515858</td>\n",
       "      <td>-0.665990</td>\n",
       "      <td>-0.773082</td>\n",
       "      <td>-0.680622</td>\n",
       "      <td>-0.891897</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288559</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.436307</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.035621</td>\n",
       "      <td>-0.372820</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.988145</td>\n",
       "      <td>-1.211827</td>\n",
       "      <td>0.728923</td>\n",
       "      <td>-0.865008</td>\n",
       "      <td>-0.004358</td>\n",
       "      <td>-0.655613</td>\n",
       "      <td>-0.199912</td>\n",
       "      <td>-0.582641</td>\n",
       "      <td>-0.151713</td>\n",
       "      <td>-0.958652</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.424823</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.270368</td>\n",
       "      <td>-0.776407</td>\n",
       "      <td>-0.689920</td>\n",
       "      <td>-0.490790</td>\n",
       "      <td>-0.707410</td>\n",
       "      <td>-0.679370</td>\n",
       "      <td>-0.786732</td>\n",
       "      <td>-0.616082</td>\n",
       "      <td>-0.712877</td>\n",
       "      <td>-0.783709</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>2.765350</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.447863</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.105420</td>\n",
       "      <td>-0.421953</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.466864</td>\n",
       "      <td>-1.500598</td>\n",
       "      <td>-0.694108</td>\n",
       "      <td>-0.814186</td>\n",
       "      <td>-1.122382</td>\n",
       "      <td>-1.153123</td>\n",
       "      <td>-0.486492</td>\n",
       "      <td>-1.154561</td>\n",
       "      <td>-0.843752</td>\n",
       "      <td>0.420476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.450001</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.367609</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-0.212263</td>\n",
       "      <td>-0.632304</td>\n",
       "      <td>1.045962</td>\n",
       "      <td>0.751332</td>\n",
       "      <td>0.244398</td>\n",
       "      <td>-0.215370</td>\n",
       "      <td>-0.173530</td>\n",
       "      <td>1.171711</td>\n",
       "      <td>0.147444</td>\n",
       "      <td>-0.747234</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.325668</td>\n",
       "      <td>-0.406229</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.784461</td>\n",
       "      <td>0.086537</td>\n",
       "      <td>1.812032</td>\n",
       "      <td>-0.292682</td>\n",
       "      <td>2.393833</td>\n",
       "      <td>0.475200</td>\n",
       "      <td>1.434618</td>\n",
       "      <td>-0.081429</td>\n",
       "      <td>2.312670</td>\n",
       "      <td>-0.342143</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.425070</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.574144</td>\n",
       "      <td>-0.035193</td>\n",
       "      <td>-0.498919</td>\n",
       "      <td>-0.371103</td>\n",
       "      <td>-0.762010</td>\n",
       "      <td>-1.188360</td>\n",
       "      <td>0.141345</td>\n",
       "      <td>-0.491294</td>\n",
       "      <td>-0.957473</td>\n",
       "      <td>0.320852</td>\n",
       "      <td>...</td>\n",
       "      <td>2.586768</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.437902</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.462832</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.337611</td>\n",
       "      <td>1.094555</td>\n",
       "      <td>1.274930</td>\n",
       "      <td>0.355719</td>\n",
       "      <td>1.394491</td>\n",
       "      <td>1.272298</td>\n",
       "      <td>1.201392</td>\n",
       "      <td>0.452614</td>\n",
       "      <td>0.970595</td>\n",
       "      <td>-0.266208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.058158</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.427885</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.166365</td>\n",
       "      <td>-0.452241</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.351054</td>\n",
       "      <td>0.777967</td>\n",
       "      <td>-0.726902</td>\n",
       "      <td>-0.223323</td>\n",
       "      <td>-1.016605</td>\n",
       "      <td>-0.926685</td>\n",
       "      <td>0.527109</td>\n",
       "      <td>-0.792227</td>\n",
       "      <td>-0.877972</td>\n",
       "      <td>0.509444</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.542996</td>\n",
       "      <td>-0.498490</td>\n",
       "      <td>-0.428225</td>\n",
       "      <td>-0.448070</td>\n",
       "      <td>-0.281712</td>\n",
       "      <td>-0.418136</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448815</td>\n",
       "      <td>-0.392477</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          $$        $_        $a        $b        $c        $d        $e  \\\n",
       "17  0.416705  0.724450  0.415587 -0.679809 -0.973339 -0.650477 -0.396736   \n",
       "5   1.120987  0.754591 -0.134707 -0.331671 -0.658595 -0.085424 -0.824043   \n",
       "33 -0.325057 -0.583721 -1.236540  1.883605 -0.211154 -0.116536 -0.431807   \n",
       "48 -1.079415  0.965113  0.604424 -0.772101 -0.413109 -0.474101 -0.162789   \n",
       "58 -1.162065 -1.478148  1.661925 -0.693171  0.422842 -0.342607 -0.757701   \n",
       "2   0.480037 -0.068256 -1.016916 -0.317620 -0.651997 -0.889553 -0.865333   \n",
       "36 -0.419297 -0.628931 -0.256807  0.941286 -0.465767  0.939080 -0.617309   \n",
       "54  0.084960 -0.116761  0.369967 -0.562680  0.821571 -0.558429  0.326681   \n",
       "46 -0.869830  1.050150  0.771172 -0.119695 -0.119732  0.866934 -0.415106   \n",
       "51 -0.584746 -0.008377 -0.342159 -0.745939 -0.604093 -0.743701 -0.442223   \n",
       "59  0.160355 -0.510266  1.069360  0.388705  1.337425 -0.555707  0.504631   \n",
       "35 -0.606974 -0.786994 -0.789039  1.411476  0.110125  0.859175 -0.563183   \n",
       "32 -0.731054 -1.069340 -0.771071  0.946844 -0.165820  1.358570  0.175429   \n",
       "10  0.374990  0.792318 -0.885106 -0.101886 -0.338209 -0.562383 -0.732698   \n",
       "56  0.470628  0.406582  0.773502 -0.494451  0.047334 -0.479151 -0.112049   \n",
       "39 -0.129934 -0.432569 -0.906443  2.341984 -0.069292  1.575497 -0.336500   \n",
       "8   0.472139  0.479092 -0.955308  1.193546 -0.155042  0.017077 -0.534344   \n",
       "40  0.212555 -0.387974 -1.012315  1.271332 -0.138710  0.496517 -0.560440   \n",
       "19 -0.242306 -0.033589 -0.869463 -0.779880 -1.070756 -0.594749 -0.658617   \n",
       "31  0.142593  0.239497  0.939542  1.550714  0.998778  3.125947  1.689082   \n",
       "28  0.146294  1.347853  1.810199 -0.025791  2.606243  2.133169  1.098803   \n",
       "49 -0.702021 -0.344423 -0.597028 -0.646175 -0.335801 -0.608541 -0.343229   \n",
       "30 -0.985239 -0.625472  1.241179 -0.734727  1.978202  1.399573  1.333163   \n",
       "38 -0.191590 -1.922174 -0.985369  2.817426 -0.495248 -0.317058 -0.414898   \n",
       "18 -0.513404  0.666082 -0.711825 -0.948278 -1.079049 -0.186843 -0.582692   \n",
       "29 -0.246754  1.116633  1.935833 -0.542458  1.698766  2.109075  1.623126   \n",
       "43 -0.501211  0.005622 -0.115629 -0.898746 -0.396357 -0.834046 -0.436594   \n",
       "34 -0.277582 -1.319759 -1.071337  2.327877  0.992075  0.615572 -0.273714   \n",
       "0   1.606565  1.290481 -1.152026 -0.852313 -0.865554 -0.941311 -0.934636   \n",
       "20  0.180774  0.166717 -0.930415  1.196283 -0.832790 -0.435373 -0.519674   \n",
       "37 -1.159575 -1.144586 -0.422678  1.926623 -0.209124  0.397376 -0.501690   \n",
       "3   0.615341  0.895382 -1.055890 -0.412484 -0.708643 -0.709166 -0.890306   \n",
       "47 -1.139190 -1.231650  0.131123 -0.947542 -0.956697 -0.970912 -0.531843   \n",
       "57 -1.252123 -1.503758  1.496069 -0.806269 -0.440554 -0.607843 -0.882973   \n",
       "13  5.740300 -0.226174 -0.032427 -0.799070 -0.938453 -1.135623  0.093709   \n",
       "22  0.700545  2.502004  0.690202 -0.316864  0.857295  0.392563  4.007624   \n",
       "44  0.076883  1.156058 -0.274081 -0.741392 -0.671524 -0.509089 -0.566280   \n",
       "24 -0.794411 -0.442621  2.248198 -0.087580  1.191377  0.305267  1.907021   \n",
       "21  0.414483 -0.441130 -1.126537 -1.003832 -0.762120 -0.290585 -0.280206   \n",
       "23  0.193931  1.394737  1.803600 -0.143164  2.904004  2.254667  3.313577   \n",
       "45  0.126770  0.753430 -0.034772 -0.963992 -0.234989 -0.729437 -0.152599   \n",
       "53 -1.058280 -1.814741  1.543265 -0.882687 -0.033399 -0.567005 -0.518076   \n",
       "9   1.222239  1.225948 -1.005696 -0.722501 -0.194068  1.367393 -0.155605   \n",
       "50 -0.353289  0.271504 -0.123417  0.290318 -0.183112  0.305302 -0.241121   \n",
       "7   0.164607 -0.232252 -1.025665 -0.628756 -0.649144 -0.875430 -0.861095   \n",
       "1   0.094656 -0.631656 -0.956070 -0.672588 -0.621613 -0.515858 -0.665990   \n",
       "55 -0.988145 -1.211827  0.728923 -0.865008 -0.004358 -0.655613 -0.199912   \n",
       "6  -0.270368 -0.776407 -0.689920 -0.490790 -0.707410 -0.679370 -0.786732   \n",
       "11 -0.466864 -1.500598 -0.694108 -0.814186 -1.122382 -1.153123 -0.486492   \n",
       "52 -0.212263 -0.632304  1.045962  0.751332  0.244398 -0.215370 -0.173530   \n",
       "27 -0.784461  0.086537  1.812032 -0.292682  2.393833  0.475200  1.434618   \n",
       "14  0.574144 -0.035193 -0.498919 -0.371103 -0.762010 -1.188360  0.141345   \n",
       "25 -0.337611  1.094555  1.274930  0.355719  1.394491  1.272298  1.201392   \n",
       "15  0.351054  0.777967 -0.726902 -0.223323 -1.016605 -0.926685  0.527109   \n",
       "\n",
       "          $f        $g        $h  ...         zr        zs        zt  \\\n",
       "17 -0.943586 -0.864334  0.838599  ...  -0.542996 -0.498490 -0.428225   \n",
       "5  -0.596442 -0.633121 -0.322912  ...  -0.542996 -0.498490 -0.335276   \n",
       "33 -0.030221  0.358247  0.851821  ...   0.710846  1.222124  2.205323   \n",
       "48 -0.937614 -0.877095 -1.127295  ...  -0.542996 -0.498490 -0.428225   \n",
       "58  4.229579  1.266662 -1.002757  ...  -0.542996 -0.498490 -0.428225   \n",
       "2  -0.604453 -0.916012 -0.876075  ...  -0.089174 -0.498490 -0.428225   \n",
       "36  0.122219  0.616054  1.578355  ...   2.391500  0.508242  1.455085   \n",
       "54 -0.429021  0.237262 -0.814364  ...  -0.542996  0.051763 -0.428225   \n",
       "46 -0.356439 -0.508251 -0.346814  ...   0.986253 -0.498490 -0.428225   \n",
       "51 -0.326390 -0.867180 -1.005471  ...  -0.542996 -0.498490 -0.428225   \n",
       "59  0.817953 -0.460466 -0.896099  ...  -0.542996 -0.498490 -0.428225   \n",
       "35  0.452142  0.291963  1.255654  ...   0.305967  1.831528  3.905810   \n",
       "32  0.288854  0.608740  3.325257  ...   1.708032  1.046023  1.279115   \n",
       "10  2.285417 -0.509801 -0.707804  ...  -0.542996 -0.498490 -0.428225   \n",
       "56  0.778703 -0.410403 -0.742613  ...  -0.542996 -0.498490 -0.428225   \n",
       "39  0.797094  0.606261  1.575821  ...   2.401112  4.551662  1.461255   \n",
       "8  -0.164344 -0.110068 -0.501298  ...  -0.542996  1.575566 -0.369437   \n",
       "40  0.162659  0.700293  1.399921  ...   1.341042  0.147864  2.374791   \n",
       "19 -0.825272 -1.081516  1.815494  ...  -0.542996 -0.498490 -0.428225   \n",
       "31  0.143302  2.819317  0.958173  ...  -0.542996 -0.498490 -0.428225   \n",
       "28  2.253571  1.174521  0.033015  ...   0.750925 -0.498490 -0.428225   \n",
       "49 -0.259520 -0.810001 -0.919208  ...  -0.542996 -0.498490 -0.428225   \n",
       "30  0.696259  1.198310  0.442127  ...  -0.542996 -0.498490 -0.428225   \n",
       "38  2.220823  1.316457  0.633571  ...   3.624157  2.360747  2.246184   \n",
       "18 -0.646036 -0.989816  0.728812  ...  -0.542996  0.580567 -0.428225   \n",
       "29  0.512309  0.970411 -0.168753  ...  -0.542996 -0.048453 -0.428225   \n",
       "43 -0.779920 -0.916733 -0.769642  ...  -0.152943 -0.498490 -0.405468   \n",
       "34  0.049932  0.552725  1.343236  ...   2.558737  1.629723  2.648219   \n",
       "0  -0.806268 -0.901110 -0.929464  ...   0.165751 -0.012193 -0.428225   \n",
       "20 -1.078235 -0.948478  0.918459  ...  -0.542996 -0.498490 -0.428225   \n",
       "37 -0.675728  1.335503  0.803739  ...   0.210715  1.570105  2.034345   \n",
       "3  -0.672412 -0.352013 -0.856915  ...  -0.008394 -0.498490 -0.428225   \n",
       "47 -0.958774 -0.673852 -1.059598  ...  -0.542996 -0.107883 -0.428225   \n",
       "57  0.252603 -0.559488 -1.093163  ...  -0.542996 -0.069008 -0.428225   \n",
       "13 -0.975817 -1.027051  1.885940  ...  -0.542996 -0.498490 -0.428225   \n",
       "22  2.059005  0.563856  0.594744  ...  -0.542996 -0.498490 -0.428225   \n",
       "44 -0.636301 -0.207808 -0.985257  ...   0.604717 -0.498490 -0.428225   \n",
       "24  0.160287  1.268669 -0.308142  ...  -0.542996 -0.498490 -0.396585   \n",
       "21  0.326144 -1.038571 -0.160662  ...  -0.542996 -0.498490 -0.428225   \n",
       "23  0.261024  2.308845  0.673495  ...  -0.542996 -0.498490 -0.428225   \n",
       "45 -1.055524 -0.488943 -0.837192  ...  -0.542996 -0.498490 -0.428225   \n",
       "53 -0.496828 -0.299632 -1.049458  ...  -0.542996 -0.498490 -0.428225   \n",
       "9   0.343720 -0.063301 -0.528314  ...  -0.542996 -0.498490 -0.428225   \n",
       "50 -0.363963 -0.621188 -0.720383  ...  -0.542996 -0.498490 -0.428225   \n",
       "7  -0.743698 -0.700542 -0.662615  ...  -0.542996 -0.498490 -0.428225   \n",
       "1  -0.773082 -0.680622 -0.891897  ...   0.288559 -0.498490 -0.428225   \n",
       "55 -0.582641 -0.151713 -0.958652  ...  -0.542996 -0.498490 -0.428225   \n",
       "6  -0.616082 -0.712877 -0.783709  ...  -0.542996  2.765350 -0.428225   \n",
       "11 -1.154561 -0.843752  0.420476  ...  -0.542996 -0.498490 -0.428225   \n",
       "52  1.171711  0.147444 -0.747234  ...  -0.542996 -0.498490 -0.325668   \n",
       "27 -0.081429  2.312670 -0.342143  ...  -0.542996 -0.498490 -0.428225   \n",
       "14 -0.491294 -0.957473  0.320852  ...   2.586768 -0.498490 -0.428225   \n",
       "25  0.452614  0.970595 -0.266208  ...  -0.058158 -0.498490 -0.428225   \n",
       "15 -0.792227 -0.877972  0.509444  ...  -0.542996 -0.498490 -0.428225   \n",
       "\n",
       "          zu        zv        zw        zx        zy        zz  bias  \n",
       "17 -0.440930 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "5  -0.443910 -0.281712 -0.418136 -0.275911  0.247255 -0.426881   1.0  \n",
       "33  2.651505 -0.281712  2.055032 -0.275911  0.646854 -0.332487   1.0  \n",
       "48 -0.453582 -0.281712 -0.418136 -0.275911 -0.448815  1.417154   1.0  \n",
       "58 -0.412311 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "2  -0.433836  0.414885 -0.404149 -0.275911 -0.052242 -0.452241   1.0  \n",
       "36  2.812389  1.970446  1.933324 -0.275911  1.260723 -0.405529   1.0  \n",
       "54 -0.450289 -0.281712 -0.418136 -0.275911 -0.448815 -0.375646   1.0  \n",
       "46 -0.438480 -0.281712 -0.418136 -0.275911 -0.003370  1.251760   1.0  \n",
       "51 -0.463310 -0.281712 -0.418136  2.072618 -0.448815  4.001936   1.0  \n",
       "59 -0.296683 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "35  2.717431  1.021407  4.723271 -0.275911  0.293051 -0.384671   1.0  \n",
       "32  1.747921 -0.281712  1.940661 -0.275911  2.829616 -0.237247   1.0  \n",
       "10 -0.365729  1.137507 -0.418136  1.633112 -0.179494 -0.422805   1.0  \n",
       "56 -0.422484 -0.281712 -0.418136 -0.275911 -0.448815 -0.398874   1.0  \n",
       "39  1.568301  3.107591  1.668815 -0.275911 -0.020030 -0.381943   1.0  \n",
       "8  -0.414230 -0.281712 -0.262866 -0.275911 -0.448815 -0.388084   1.0  \n",
       "40  2.198069  1.164244  0.801246 -0.275911  0.648762 -0.392260   1.0  \n",
       "19 -0.463310 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "31 -0.404736 -0.281712 -0.362545 -0.275911 -0.448815 -0.452241   1.0  \n",
       "28 -0.442301 -0.281712 -0.418136 -0.275911 -0.448815 -0.060900   1.0  \n",
       "49 -0.463310 -0.281712 -0.418136 -0.275911 -0.448815  1.195835   1.0  \n",
       "30 -0.463310 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "38  2.818240  6.114676  1.636761 -0.275911  1.978827 -0.319574   1.0  \n",
       "18 -0.463310 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "29 -0.457985 -0.281712 -0.418136 -0.275911 -0.448815 -0.431359   1.0  \n",
       "43 -0.437977 -0.281712 -0.418136 -0.275911 -0.107967  1.311096   1.0  \n",
       "34  1.626710 -0.281712  1.302574 -0.275911  0.454667 -0.353493   1.0  \n",
       "0  -0.440295 -0.281712 -0.418136 -0.275911 -0.448815 -0.429677   1.0  \n",
       "20 -0.338112 -0.281712 -0.374928 -0.275911 -0.448815 -0.452241   1.0  \n",
       "37  2.326904 -0.281712  2.067396 -0.275911 -0.009728 -0.356259   1.0  \n",
       "3  -0.450290 -0.281712 -0.418136 -0.275911 -0.137374 -0.452241   1.0  \n",
       "47 -0.458689 -0.281712 -0.418136 -0.275911 -0.282992  3.589403   1.0  \n",
       "57 -0.382004 -0.281712 -0.398845 -0.275911 -0.448815 -0.452241   1.0  \n",
       "13 -0.438523 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "22 -0.316873 -0.281712 -0.418136  3.862169  0.426871 -0.452241   1.0  \n",
       "44 -0.435358 -0.281712 -0.418136 -0.275911 -0.114505  2.142028   1.0  \n",
       "24 -0.445700 -0.281712 -0.367995 -0.275911 -0.448815 -0.452241   1.0  \n",
       "21 -0.463310 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "23 -0.450905 -0.281712 -0.347494 -0.275911 -0.226263 -0.403592   1.0  \n",
       "45 -0.443641 -0.281712 -0.418136 -0.275911 -0.448815  1.167534   1.0  \n",
       "53 -0.438063 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "9  -0.431100 -0.281712 -0.295855 -0.275911  1.862587 -0.452241   1.0  \n",
       "50 -0.360791 -0.281712 -0.369487 -0.275911 -0.448815  1.909708   1.0  \n",
       "7  -0.455372 -0.281712 -0.418136 -0.275911 -0.448815 -0.389980   1.0  \n",
       "1  -0.436307 -0.281712 -0.418136 -0.275911  0.035621 -0.372820   1.0  \n",
       "55 -0.424823 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "6  -0.447863 -0.281712 -0.418136 -0.275911  0.105420 -0.421953   1.0  \n",
       "11 -0.450001 -0.281712 -0.367609 -0.275911 -0.448815 -0.452241   1.0  \n",
       "52 -0.406229 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "27 -0.425070 -0.281712 -0.418136 -0.275911 -0.448815 -0.452241   1.0  \n",
       "14 -0.437902 -0.281712 -0.418136 -0.275911  0.462832 -0.452241   1.0  \n",
       "25 -0.427885 -0.281712 -0.418136 -0.275911 -0.166365 -0.452241   1.0  \n",
       "15 -0.448070 -0.281712 -0.418136 -0.275911 -0.448815 -0.392477   1.0  \n",
       "\n",
       "[54 rows x 785 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_vector = np.ones([X_train.shape[0], 1])\n",
    "X_train['bias'] = bias_vector\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise weight matrix with small weights\n",
    "\n",
    "np.random.seed(seed=200)\n",
    "\n",
    "W = np.random.randn(X_train.shape[1], len(lb.classes_)) * 0.0001\n",
    "#W = np.zeros([X.shape[1], len(lb.classes_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dimensions are right. The dot product of a specific row from X_train and the weight matrix W constitutes a forward pass and calculates the score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 6)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 785)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002753</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5\n",
       "2 -0.002753  0.001105  0.000354 -0.000783  0.003842 -0.000011"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5:6].dot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the values for the highest score of the dot product is not the score of the true label. Our aim is to change this by implementing a support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.003842\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5:6].dot(W).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.001105\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5:6].dot(W)[y_train[5:6].argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: we follow kind of a naive implementation. The aim is to be able to understand what is going on!\n",
    "\n",
    "In order to quantify how good (or how bad) our weight matrix W can predict the data in our training set, we need to implement a loss function. Here we take a go at the hinge loss, which tries to predict the correct class with a margin of at least one to all other classes (or in this case, like presented in Goldberg, to the class which does not equal the true class, but which scores highest). In my understanding, this is a one-vs-one approach (true class vs. class with highest score (but doesn't equal the true class))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hinge_loss(x, y, W, index):\n",
    "    \"\"\"\n",
    "    Calculates the loss of a single data point by taking the prediction of the correct value and the the prediction of\n",
    "    the value of next highest score, following Crammer and Singer (2001)\n",
    "    :param x: sample point x as a vector\n",
    "    :param y: correct label y for x as a vector\n",
    "    :param W: weight matrix\n",
    "    :param index: column index of data matrix X\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    y_index = y[index].argmax()\n",
    "    y_value = x.dot(W)[y_index]\n",
    "    y_hat_max_value = np.delete(x.dot(W), y_index).max()\n",
    "    #for j in range(0, y.shape[1]):  # in case we wanted to classify against all other classes (one-vs-all) --> currently one-vs-one\n",
    "        #if j == y_index:\n",
    "            #continue\n",
    "    loss += max(0, 1 - (y_value - y_hat_max_value))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With matrix multiplication, we could get all the scores at once. In the following, however, we focus on an approach which takes sample by sample and calculates the loss and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X_train.dot(W)  # simple matrix multiplication to get all scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.007375</td>\n",
       "      <td>-0.005236</td>\n",
       "      <td>-0.004241</td>\n",
       "      <td>-0.006293</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.003541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005800</td>\n",
       "      <td>-0.006748</td>\n",
       "      <td>0.001192</td>\n",
       "      <td>-0.000476</td>\n",
       "      <td>0.000874</td>\n",
       "      <td>-0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.001369</td>\n",
       "      <td>-0.001093</td>\n",
       "      <td>-0.000351</td>\n",
       "      <td>-0.000555</td>\n",
       "      <td>0.003478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>-0.000161</td>\n",
       "      <td>-0.002081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000668</td>\n",
       "      <td>-0.000811</td>\n",
       "      <td>0.006183</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>-0.002477</td>\n",
       "      <td>0.000341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002753</td>\n",
       "      <td>0.001105</td>\n",
       "      <td>0.000354</td>\n",
       "      <td>-0.000783</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>-0.000011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000501</td>\n",
       "      <td>-0.005079</td>\n",
       "      <td>-0.002875</td>\n",
       "      <td>0.004025</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>-0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.001154</td>\n",
       "      <td>0.004904</td>\n",
       "      <td>0.003003</td>\n",
       "      <td>0.005856</td>\n",
       "      <td>-0.001277</td>\n",
       "      <td>0.004642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.002021</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.001625</td>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.001955</td>\n",
       "      <td>-0.004749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.000868</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001439</td>\n",
       "      <td>0.001762</td>\n",
       "      <td>-0.004693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000071</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.001723</td>\n",
       "      <td>0.000499</td>\n",
       "      <td>0.003562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.006516</td>\n",
       "      <td>0.003930</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.004022</td>\n",
       "      <td>-0.002261</td>\n",
       "      <td>0.003315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.001123</td>\n",
       "      <td>-0.004277</td>\n",
       "      <td>0.001690</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.000222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.003581</td>\n",
       "      <td>0.001621</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>-0.002154</td>\n",
       "      <td>-0.000526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.000096</td>\n",
       "      <td>-0.003035</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.001225</td>\n",
       "      <td>0.001627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.004394</td>\n",
       "      <td>-0.003622</td>\n",
       "      <td>-0.001971</td>\n",
       "      <td>-0.002788</td>\n",
       "      <td>-0.004207</td>\n",
       "      <td>0.003716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004450</td>\n",
       "      <td>-0.003342</td>\n",
       "      <td>-0.002252</td>\n",
       "      <td>-0.001061</td>\n",
       "      <td>-0.003008</td>\n",
       "      <td>0.001828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.006362</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.001288</td>\n",
       "      <td>0.003907</td>\n",
       "      <td>-0.000175</td>\n",
       "      <td>0.000555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.001944</td>\n",
       "      <td>-0.004439</td>\n",
       "      <td>-0.003163</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.001904</td>\n",
       "      <td>0.001904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.000498</td>\n",
       "      <td>-0.000503</td>\n",
       "      <td>-0.002981</td>\n",
       "      <td>0.000620</td>\n",
       "      <td>-0.002635</td>\n",
       "      <td>-0.004004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.005999</td>\n",
       "      <td>-0.001002</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.004428</td>\n",
       "      <td>-0.002311</td>\n",
       "      <td>-0.003604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.004737</td>\n",
       "      <td>0.003291</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.001072</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>-0.003264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.001236</td>\n",
       "      <td>-0.002932</td>\n",
       "      <td>-0.000538</td>\n",
       "      <td>0.005038</td>\n",
       "      <td>-0.000874</td>\n",
       "      <td>-0.004264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.007237</td>\n",
       "      <td>-0.000848</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.000865</td>\n",
       "      <td>0.005419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.002557</td>\n",
       "      <td>-0.002650</td>\n",
       "      <td>-0.001386</td>\n",
       "      <td>-0.004749</td>\n",
       "      <td>-0.002221</td>\n",
       "      <td>0.002115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.000911</td>\n",
       "      <td>-0.000142</td>\n",
       "      <td>-0.000126</td>\n",
       "      <td>0.004361</td>\n",
       "      <td>-0.001603</td>\n",
       "      <td>-0.002271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.001229</td>\n",
       "      <td>0.000771</td>\n",
       "      <td>-0.001278</td>\n",
       "      <td>0.001028</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>-0.002371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.004864</td>\n",
       "      <td>-0.002478</td>\n",
       "      <td>0.002698</td>\n",
       "      <td>-0.003659</td>\n",
       "      <td>-0.002117</td>\n",
       "      <td>0.004789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000348</td>\n",
       "      <td>0.001736</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.000464</td>\n",
       "      <td>0.000041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.005416</td>\n",
       "      <td>-0.005623</td>\n",
       "      <td>-0.005980</td>\n",
       "      <td>-0.001542</td>\n",
       "      <td>0.000970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.003898</td>\n",
       "      <td>-0.001539</td>\n",
       "      <td>0.004768</td>\n",
       "      <td>-0.000059</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.001577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002665</td>\n",
       "      <td>0.001003</td>\n",
       "      <td>-0.001753</td>\n",
       "      <td>-0.001869</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.002516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.001252</td>\n",
       "      <td>0.003714</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.004127</td>\n",
       "      <td>0.001014</td>\n",
       "      <td>-0.001287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.002596</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.001891</td>\n",
       "      <td>0.003162</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.001880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.004556</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>-0.004093</td>\n",
       "      <td>-0.002579</td>\n",
       "      <td>0.000769</td>\n",
       "      <td>-0.001028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.003457</td>\n",
       "      <td>0.005865</td>\n",
       "      <td>0.002181</td>\n",
       "      <td>0.001424</td>\n",
       "      <td>-0.004283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.000614</td>\n",
       "      <td>0.003099</td>\n",
       "      <td>-0.000031</td>\n",
       "      <td>-0.002291</td>\n",
       "      <td>0.002191</td>\n",
       "      <td>-0.003452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.001853</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.000470</td>\n",
       "      <td>0.002382</td>\n",
       "      <td>-0.003064</td>\n",
       "      <td>-0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002691</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>-0.003639</td>\n",
       "      <td>-0.006247</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>-0.003534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.000290</td>\n",
       "      <td>-0.000458</td>\n",
       "      <td>0.000147</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>-0.003822</td>\n",
       "      <td>-0.003453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001829</td>\n",
       "      <td>0.001819</td>\n",
       "      <td>0.001156</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>0.004374</td>\n",
       "      <td>-0.003296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>0.002808</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.001124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001176</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>-0.004926</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.000646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.001926</td>\n",
       "      <td>-0.000948</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>-0.003075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000990</td>\n",
       "      <td>-0.001958</td>\n",
       "      <td>0.002040</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>0.004347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001437</td>\n",
       "      <td>-0.004407</td>\n",
       "      <td>0.001521</td>\n",
       "      <td>0.002165</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.000626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000721</td>\n",
       "      <td>0.003840</td>\n",
       "      <td>0.002250</td>\n",
       "      <td>-0.000666</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.001701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000800</td>\n",
       "      <td>-0.001322</td>\n",
       "      <td>0.001849</td>\n",
       "      <td>0.001653</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.000178</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.004032</td>\n",
       "      <td>-0.004319</td>\n",
       "      <td>-0.006708</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>0.001576</td>\n",
       "      <td>0.004239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000393</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>0.005173</td>\n",
       "      <td>-0.001648</td>\n",
       "      <td>-0.001479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.002822</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>-0.001504</td>\n",
       "      <td>0.000835</td>\n",
       "      <td>-0.000193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.002860</td>\n",
       "      <td>-0.001568</td>\n",
       "      <td>-0.004665</td>\n",
       "      <td>-0.004957</td>\n",
       "      <td>0.003121</td>\n",
       "      <td>0.001370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.002669</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>-0.001735</td>\n",
       "      <td>0.000593</td>\n",
       "      <td>-0.000995</td>\n",
       "      <td>-0.002292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.002085</td>\n",
       "      <td>-0.002384</td>\n",
       "      <td>-0.004894</td>\n",
       "      <td>-0.005947</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "17 -0.007375 -0.005236 -0.004241 -0.006293  0.000811  0.003541\n",
       "5  -0.005800 -0.006748  0.001192 -0.000476  0.000874 -0.001014\n",
       "33  0.003552  0.001369 -0.001093 -0.000351 -0.000555  0.003478\n",
       "48  0.002507  0.002691  0.002067  0.000304 -0.000161 -0.002081\n",
       "58  0.000668 -0.000811  0.006183  0.002916 -0.002477  0.000341\n",
       "2  -0.002753  0.001105  0.000354 -0.000783  0.003842 -0.000011\n",
       "36  0.000501 -0.005079 -0.002875  0.004025  0.001413 -0.000616\n",
       "54 -0.001154  0.004904  0.003003  0.005856 -0.001277  0.004642\n",
       "46 -0.002021  0.000087  0.001625 -0.000911 -0.001955 -0.004749\n",
       "51 -0.000868  0.004471  0.001184  0.001439  0.001762 -0.004693\n",
       "59  0.000071  0.006010  0.003144  0.001723  0.000499  0.003562\n",
       "35  0.006516  0.003930 -0.000196  0.004022 -0.002261  0.003315\n",
       "32  0.004159  0.001123 -0.004277  0.001690 -0.004665 -0.000222\n",
       "10  0.000327  0.003581  0.001621  0.000102 -0.002154 -0.000526\n",
       "56 -0.000096 -0.003035  0.002566  0.001783  0.001225  0.001627\n",
       "39  0.004394 -0.003622 -0.001971 -0.002788 -0.004207  0.003716\n",
       "8   0.004450 -0.003342 -0.002252 -0.001061 -0.003008  0.001828\n",
       "40  0.006362  0.001307  0.001288  0.003907 -0.000175  0.000555\n",
       "19 -0.001944 -0.004439 -0.003163 -0.003584 -0.001904  0.001904\n",
       "31 -0.000498 -0.000503 -0.002981  0.000620 -0.002635 -0.004004\n",
       "28 -0.005999 -0.001002  0.001705  0.004428 -0.002311 -0.003604\n",
       "49  0.004737  0.003291  0.000018  0.001072  0.000454 -0.003264\n",
       "30 -0.001236 -0.002932 -0.000538  0.005038 -0.000874 -0.004264\n",
       "38  0.007237 -0.000848  0.004748  0.002397  0.000865  0.005419\n",
       "18 -0.002557 -0.002650 -0.001386 -0.004749 -0.002221  0.002115\n",
       "29 -0.000911 -0.000142 -0.000126  0.004361 -0.001603 -0.002271\n",
       "43 -0.001229  0.000771 -0.001278  0.001028  0.000249 -0.002371\n",
       "34  0.004864 -0.002478  0.002698 -0.003659 -0.002117  0.004789\n",
       "0  -0.000348  0.001736  0.003521 -0.000687 -0.000464  0.000041\n",
       "20 -0.001600 -0.005416 -0.005623 -0.005980 -0.001542  0.000970\n",
       "37  0.003898 -0.001539  0.004768 -0.000059  0.000453  0.001577\n",
       "3  -0.002665  0.001003 -0.001753 -0.001869  0.000030  0.002516\n",
       "47 -0.001252  0.003714  0.000888  0.004127  0.001014 -0.001287\n",
       "57  0.002596  0.002544  0.001891  0.003162  0.000701  0.001880\n",
       "13 -0.004556 -0.000557 -0.004093 -0.002579  0.000769 -0.001028\n",
       "22  0.000690  0.003457  0.005865  0.002181  0.001424 -0.004283\n",
       "44 -0.000614  0.003099 -0.000031 -0.002291  0.002191 -0.003452\n",
       "24 -0.001853 -0.000107 -0.000470  0.002382 -0.003064 -0.000985\n",
       "21  0.002691 -0.002476 -0.003639 -0.006247  0.000922 -0.003534\n",
       "23 -0.000290 -0.000458  0.000147  0.005085 -0.003822 -0.003453\n",
       "45  0.001829  0.001819  0.001156 -0.002591  0.004374 -0.003296\n",
       "53  0.000478  0.001626  0.002808  0.000243  0.000730  0.001124\n",
       "9   0.001176  0.003632  0.004192 -0.004926  0.000872  0.000646\n",
       "50  0.001926 -0.000948  0.000400 -0.000299  0.000042 -0.003075\n",
       "7   0.000990 -0.001958  0.002040  0.003675  0.001698  0.004347\n",
       "1  -0.001437 -0.004407  0.001521  0.002165  0.002345  0.000626\n",
       "55  0.000721  0.003840  0.002250 -0.000666  0.000077  0.001701\n",
       "6  -0.000800 -0.001322  0.001849  0.001653  0.003897  0.000178\n",
       "11 -0.004032 -0.004319 -0.006708 -0.005068  0.001576  0.004239\n",
       "52  0.000393  0.002854  0.000962  0.005173 -0.001648 -0.001479\n",
       "27 -0.002822  0.000698  0.000301 -0.001504  0.000835 -0.000193\n",
       "14 -0.002860 -0.001568 -0.004665 -0.004957  0.003121  0.001370\n",
       "25 -0.002669  0.000255 -0.001735  0.000593 -0.000995 -0.002292\n",
       "15 -0.002085 -0.002384 -0.004894 -0.005947  0.002342  0.002370"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, W):\n",
    "    \"\"\"\n",
    "    compute the gradient\n",
    "    :param X: data matrix (train) \n",
    "    :param y: the corresponding \n",
    "    :param W: weight matrix\n",
    "    :return: loss and Jacobian dW with all gradients\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for index, x in enumerate(X.as_matrix()):\n",
    "        y_index = y[index].argmax()\n",
    "        y_value = x.dot(W)[y_index]\n",
    "        y_hat_max_value = np.delete(x.dot(W), y_index).max()\n",
    "        loss = max(0, 1 - (y_value - y_hat_max_value))\n",
    "        total_loss += loss\n",
    "        y_hat_max_index = np.delete(x.dot(W), y_index).argmax() + 1\n",
    "        if loss > 0:  # not sure whether we need this if statement\n",
    "            dW[:, y_hat_max_index] += x.transpose()\n",
    "            dW[:, y_index] -= x.transpose()\n",
    "            \n",
    "    return total_loss, dW\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, W, eta, steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for a number of times with a fixed learning rate eta\n",
    "    :param X: data matrix\n",
    "    :param y: labels\n",
    "    :param W: weight matrix\n",
    "    :param eta: learning rate\n",
    "    :param steps: number of times gradient descent should be performed\n",
    "    :return: learned representation matrix W_learned\n",
    "    \"\"\"\n",
    "    W_learned = W.copy()\n",
    "    \n",
    "    for step in range(0, steps):\n",
    "        loss, dW = gradient(X, y, W_learned)\n",
    "        print(loss)\n",
    "        W_learned = W_learned - eta * dW\n",
    "        \n",
    "    return W_learned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54.206118975295375\n",
      "21.486670396698702\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "W_star = gradient_descent(X_train, y_train, W, eta=0.001, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Let's test if our learned representation of the data is any good at classifying the data in the test set. Of course we need the bias in our test set as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_vector_test = np.ones([X_test.shape[0], 1])\n",
    "X_test['bias'] = bias_vector_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "3 3\n",
      "3 3\n",
      "4 4\n",
      "0 0\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_test.dot(W_star).as_matrix()):\n",
    "    pred = x.argmax()\n",
    "    true_label = y_test[index].argmax()\n",
    "    print(pred, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad! But Goldberg mentioned something about regularisation, so we should take this into account as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_reg(X, y, W, lam):\n",
    "    \"\"\"\n",
    "    compute the gradient\n",
    "    :param X: data matrix (train) \n",
    "    :param y: the corresponding \n",
    "    :param W: weight matrix\n",
    "    :param lam: reguliser lambda\n",
    "    :return: Jacobian dW with all gradients\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape)\n",
    "    \n",
    "    total_loss = 0.0\n",
    "    \n",
    "    for index, x in enumerate(X.as_matrix()):\n",
    "        y_index = y[index].argmax()\n",
    "        y_value = x.dot(W)[y_index]\n",
    "        y_hat_max_value = np.delete(x.dot(W), y_index).max()\n",
    "        loss = max(0, 1 - (y_value - y_hat_max_value)) + lam * np.linalg.norm(W, 2)\n",
    "        total_loss += loss\n",
    "        y_hat_max_index = np.delete(x.dot(W), y_index).argmax() + 1\n",
    "        if loss > 0:  # not sure whether we need this if statement\n",
    "            dW[:, y_hat_max_index] += x.transpose()\n",
    "            dW[:, y_index] -= x.transpose()\n",
    "        \n",
    "    dW += 2 * lam * W\n",
    "            \n",
    "    return total_loss, dW\n",
    "\n",
    "def gradient_descent_reg(X, y, W, eta, steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for a number of times with a fixed learning rate eta\n",
    "    :param X: data matrix\n",
    "    :param y: labels\n",
    "    :param W: weight matrix\n",
    "    :param eta: learning rate\n",
    "    :param steps: number of times gradient descent should be performed\n",
    "    :return: learned representation matrix W_learned\n",
    "    \"\"\"\n",
    "    W_learned = W.copy()\n",
    "    \n",
    "    for step in range(0, steps):\n",
    "        loss, dW = gradient_reg(X, y, W_learned, 10)\n",
    "        print(loss)\n",
    "        W_learned = W_learned - eta * dW\n",
    "        \n",
    "    return W_learned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55.78230906772709\n",
      "203.21634783496432\n",
      "283.08255355815544\n",
      "394.5485516212814\n",
      "524.8345169607236\n",
      "635.7249949392508\n",
      "748.132597614688\n",
      "864.2076556461765\n",
      "991.654462158203\n",
      "1086.838496318409\n"
     ]
    }
   ],
   "source": [
    "W_star_reg = gradient_descent_reg(X_train, y_train, W, eta=0.001, steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "3 3\n",
      "3 3\n",
      "4 4\n",
      "0 0\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_test.dot(W_star_reg).as_matrix()):\n",
    "    pred = x.argmax()\n",
    "    true_label = y_test[index].argmax()\n",
    "    print(pred, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the two different weight matrices (one regularised, the other not), we notice the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0037736 ,  0.00624098, -0.00675007,  0.01021503, -0.00699125,\n",
       "         0.00118419],\n",
       "       [-0.00829818,  0.00381192, -0.01537289,  0.00282321,  0.0122733 ,\n",
       "         0.00493589],\n",
       "       [-0.00743025, -0.00597328,  0.01602757, -0.00920754,  0.01962092,\n",
       "        -0.01269763],\n",
       "       [ 0.01578216, -0.00314716, -0.00245102, -0.00663084,  0.0035217 ,\n",
       "        -0.0071784 ],\n",
       "       [-0.00068613, -0.00424234,  0.00507315, -0.00952214,  0.02428383,\n",
       "        -0.0148356 ]])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.03482627,  0.04752469, -0.04082376,  0.06112236, -0.0103456 ,\n",
       "        -0.02253813],\n",
       "       [-0.07915388,  0.03398947, -0.08130804, -0.01123183,  0.08562072,\n",
       "         0.05224025],\n",
       "       [-0.07123135, -0.05690076,  0.07710793, -0.06656845,  0.11861532,\n",
       "        -0.00071539],\n",
       "       [ 0.15165281, -0.06477741, -0.02128677, -0.02910499,  0.00058112,\n",
       "        -0.03715841],\n",
       "       [-0.00627308, -0.04574701,  0.01419929, -0.09809548,  0.15285981,\n",
       "        -0.01687954]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star_reg[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By the way ...\n",
    "### In scikit-learn it's much easier to implement this :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=0,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0, multi_class='crammer_singer', loss='hinge')\n",
    "clf.fit(X_train, train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'fi', 'fi', 'fr', 'de', 'it'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     en\n",
       "12    fi\n",
       "16    fi\n",
       "26    fr\n",
       "41    de\n",
       "42    it\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with our naive implementation, we do not much worse than with scikit's. scikit's implementation is of course much more elaborate and uses the vectorised operation and possibly other optimisation techniques in order to make its SVM (or SVC) better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
