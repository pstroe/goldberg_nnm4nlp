{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification - Language Classification\n",
    "\n",
    "This notebook implements the method presented in Goldberg's [2017] book \"Neural Network Methods for Natural Language Processing\". It shows the steps you need to go through in order to successfully train a classifier, and it should also, so I hope, illustrate the notational differences between Goldberg and standard machine learning literature.\n",
    "\n",
    "$NOTE$: There is no cross-validation etc. to find optimal parameters. This is simply to show how multi-class classification works. This will be part of a tutorial session and all other concepts will be explained there.\n",
    "\n",
    "Author: Phillip Ströbel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting and cleaning the data\n",
    "\n",
    "The data consists of downloaded Wikipedia articles (see `urls.txt`) in German, English, French, Spanish, Italian and Finnish (instead of \"O\" in Goldberg). The data is in HTML, so we need to some preprocessing to get the text out of it. We also restrict ourselfes to the characters from a to z in the alphabet (as described in Goldberg). In this fashion, we get rid of all the Umlauts (ä, ö, ü) and all other characters with diacritics (as, e.g., the é or ç in French). Note however, that if these characters ocurring in bigrams would probably be good features. In some way, we still keep the information \"special character\" by not fully deleting the character, but by replacing it by the dollar sign \"\\$\". Furthermore, we replace all punctuation marks and digits by dollar signs as well. As such, all special characters, digits, and punctuation marks are mapped to $. The space will be replaced by an underscore \"\\_\". We then represent each langauge by 28 characters, as is suggested by Goldberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning HTML\n",
    "We first strip the HTML to get only the text of the Wikipedia page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the html files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "from collections import defaultdict\n",
    "\n",
    "seed = np.random.seed(seed=200)  # set a seed for random, so results are reproducible\n",
    "\n",
    "article_dict = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "regex = r'[\\n ]{2,}'\n",
    "pattern = re.compile(regex)\n",
    "\n",
    "urls = open('urls.txt', 'r').readlines()\n",
    "\n",
    "for index, url in enumerate(urls):\n",
    "    language = url[8:10]\n",
    "    doc_id = 'doc_%d' % index\n",
    "    html = urlopen(url.strip()).read()    \n",
    "    soup = BeautifulSoup(html, 'html.parser')\n",
    "    raw = soup.body.get_text()  # only get text from the text body (this excludes headers and should exclude navigation bars)\n",
    "    raw = re.sub(pattern, ' ', raw)  # replace multiple breaks and spaces by only one space\n",
    "    raw = re.sub(r'\\n', ' ', raw)  # replace every line break with a space\n",
    "    article_dict[language][doc_id] = raw.lower()  # assign each text to its language and lower all uppercase characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing --> prepare the text\n",
    "replace special characters and digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_dict = defaultdict(lambda: defaultdict(str))\n",
    "\n",
    "abc = r'[a-z]'\n",
    "abc_pattern = re.compile(abc)\n",
    "\n",
    "for lang, doc in article_dict.items():\n",
    "    for doc, text in doc.items():\n",
    "        for char in text:\n",
    "            if re.match(abc_pattern, char):\n",
    "                preprocessed_dict[lang][doc] += char\n",
    "            elif re.match(' ', char):\n",
    "                preprocessed_dict[lang][doc] += '_'\n",
    "            else:\n",
    "                preprocessed_dict[lang][doc] += '$'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count bigrams --> Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of bigrams will be our only feature. We could extend this by taking into account other n-grams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "charset = 'abcdefghijklmnopqrstuvwxyz$_'  # define the character set we want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations_with_replacement, permutations\n",
    "\n",
    "def bigrams(text):\n",
    "    \"\"\"\n",
    "    Function to extract bigrams from text and calculate their distribution\n",
    "    :param text: text string\n",
    "    :return: dictionary containing bigrams as keys, and the normalised count as values\n",
    "    \"\"\"\n",
    "    combs = combinations_with_replacement(charset, 2)\n",
    "    perms = permutations(charset, 2)\n",
    "    bigram_dict = dict()\n",
    "    \n",
    "    for comb in set(list(combs) + list(perms)):\n",
    "        bigram_dict[''.join(comb)] = 0\n",
    "        \n",
    "    doc_length = len(text)\n",
    "    \n",
    "    for index in range(0, len(text)-1):\n",
    "        bigram = text[index] + text[index+1]\n",
    "        bigram_dict[bigram] += 1\n",
    "                \n",
    "    for bigram, count in bigram_dict.items():\n",
    "        bigram_dict[bigram] = count/doc_length\n",
    "\n",
    "    return bigram_dict              "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Put data into pandas dataframe\n",
    "The pandas dataframe allows us to conveniently represent all the data we need in one table. So let's do this. But first we need to extract the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigram_dict_full = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for lang, doc in preprocessed_dict.items():\n",
    "    for doc, text in sorted(doc.items()):\n",
    "        bigram_dict = bigrams(text)\n",
    "        bigram_dict_full[lang][doc] = bigram_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$</th>\n",
       "      <th>$_</th>\n",
       "      <th>$a</th>\n",
       "      <th>$b</th>\n",
       "      <th>$c</th>\n",
       "      <th>$d</th>\n",
       "      <th>$e</th>\n",
       "      <th>$f</th>\n",
       "      <th>$g</th>\n",
       "      <th>$h</th>\n",
       "      <th>...</th>\n",
       "      <th>zq</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100699</td>\n",
       "      <td>0.036878</td>\n",
       "      <td>0.000291</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.000332</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>0.000239</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062188</td>\n",
       "      <td>0.028909</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072008</td>\n",
       "      <td>0.031248</td>\n",
       "      <td>0.000444</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.075458</td>\n",
       "      <td>0.035249</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.064235</td>\n",
       "      <td>0.032112</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000301</td>\n",
       "      <td>0.000735</td>\n",
       "      <td>0.000295</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         $$        $_        $a        $b        $c        $d        $e  \\\n",
       "0  0.100699  0.036878  0.000291  0.000221  0.000332  0.000163  0.000239   \n",
       "1  0.062188  0.028909  0.000513  0.000322  0.000520  0.000356  0.000629   \n",
       "2  0.072008  0.031248  0.000444  0.000519  0.000497  0.000187  0.000340   \n",
       "3  0.075458  0.035249  0.000400  0.000466  0.000453  0.000268  0.000303   \n",
       "4  0.064235  0.032112  0.000344  0.000301  0.000735  0.000295  0.000476   \n",
       "\n",
       "         $f        $g        $h    ...           zq        zr        zs   zt  \\\n",
       "0  0.000181  0.000099  0.000151    ...     0.000000  0.000006  0.000006  0.0   \n",
       "1  0.000192  0.000185  0.000171    ...     0.000007  0.000007  0.000000  0.0   \n",
       "2  0.000246  0.000093  0.000179    ...     0.000000  0.000004  0.000000  0.0   \n",
       "3  0.000224  0.000312  0.000189    ...     0.000000  0.000004  0.000000  0.0   \n",
       "4  0.000313  0.000271  0.000187    ...     0.000000  0.000000  0.000006  0.0   \n",
       "\n",
       "         zu        zv        zw   zx        zy        zz  \n",
       "0  0.000023  0.000000  0.000000  0.0  0.000000  0.000006  \n",
       "1  0.000027  0.000000  0.000000  0.0  0.000014  0.000021  \n",
       "2  0.000030  0.000004  0.000004  0.0  0.000011  0.000000  \n",
       "3  0.000013  0.000000  0.000000  0.0  0.000009  0.000000  \n",
       "4  0.000006  0.000000  0.000000  0.0  0.000000  0.000000  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "col_names = ['y'] + sorted(bigram_dict_full['en']['doc_0'].keys())\n",
    "my_df = dict()\n",
    "\n",
    "for col in col_names:\n",
    "    my_df[col] = list()\n",
    "    \n",
    "df = pd.DataFrame(my_df)\n",
    "\n",
    "for lang, doc in bigram_dict_full.items():\n",
    "    for key, value in doc.items():\n",
    "        df_obj = value\n",
    "        df_obj['y'] = lang\n",
    "        df = df.append(df_obj, ignore_index=True)\n",
    "        \n",
    "df.head()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60, 785)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we split the data into the label vector \\begin{equation}\\mathbf{y}\\end{equation} and a training data matrix \\begin{equation}\\mathbf{X}\\end{equation}. But first, we shuffle the df and split it into a training and a test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover, it is necessary for many machine learning tasks to standardise the data. Our aim is for each feature to be represented by a column vector in which values have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_point(datapoint, mean, std):\n",
    "    \"\"\"\n",
    "    normalise a datapoint to zero mean and unit variance.\n",
    "    :param datapoint: value as a float\n",
    "    :param mean: mean of data vector x\n",
    "    :param std: standard deviation of data vector x\n",
    "    :return: normalised datapoint (float)\n",
    "    \"\"\"\n",
    "    return (datapoint - mean)/std\n",
    "\n",
    "def normalise_matrix(matrix):\n",
    "    \"\"\"\n",
    "    normalises the data matrix\n",
    "    :param matrix: input matrix\n",
    "    :return: normalised matrix\n",
    "    \"\"\"\n",
    "    train_normalised = matrix.copy()\n",
    "    \n",
    "    for col in matrix:\n",
    "        try:\n",
    "            mean = matrix[col].mean()\n",
    "            std = matrix[col].std()\n",
    "            for index, item in enumerate(matrix[col]):\n",
    "                train_normalised.loc[index, col] = normalise_point(item, mean, std)\n",
    "        except ZeroDivisionError:\n",
    "            train_normalised.loc[index, col] = 0.0\n",
    "        except TypeError:\n",
    "            continue\n",
    "    return train_normalised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = normalise_matrix(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into a train set and a test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df_norm.sample(frac=0.9, random_state=seed)\n",
    "test = df_norm.drop(train.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the different sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for training\n",
    "y_train = train.y\n",
    "X_train = train.drop('y', axis=1)\n",
    "\n",
    "# for testing\n",
    "y_test = test.y\n",
    "X_test = test.drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples shape:  (54, 784)\n",
      "Training labels shape:  (54,)\n",
      "Test samples shape:  (6, 784)\n",
      "Test labels shape:  (6,)\n"
     ]
    }
   ],
   "source": [
    "print('Training samples shape: ', X_train.shape)\n",
    "print('Training labels shape: ', y_train.shape)\n",
    "print('Test samples shape: ', X_test.shape)\n",
    "print('Test labels shape: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should binarise our labels, although libraries like sklearn can also deal with non-numeric data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "lb = preprocessing.LabelBinarizer()\n",
    "lb.fit(['en', 'fr', 'de', 'it', 'es', 'fi'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['de', 'en', 'es', 'fi', 'fr', 'it'], dtype='<U2')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do this for both our training and test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = lb.transform(y_train)\n",
    "y_test = lb.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Labels are now one-hot encoded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We almost have everything now. However, we need to take care of the bias and the weight matrix. The hypothesis ŷ is given by:\n",
    "\\begin{equation}\n",
    "\\mathbf{\\hat{y}}=\\mathbf{x}\\cdot\\mathbf{W}+\\mathbf{b}\n",
    "\\end{equation}\n",
    "We can achieve this by appending 1 to each feature vector x, and the whole weight vector b to the weight matrix W. This is called the bias trick. Note that the dimensions of X_train change, and that the weight matrix W will have match the dimensions (same number of rows as X has columns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>$$</th>\n",
       "      <th>$_</th>\n",
       "      <th>$a</th>\n",
       "      <th>$b</th>\n",
       "      <th>$c</th>\n",
       "      <th>$d</th>\n",
       "      <th>$e</th>\n",
       "      <th>$f</th>\n",
       "      <th>$g</th>\n",
       "      <th>$h</th>\n",
       "      <th>...</th>\n",
       "      <th>zr</th>\n",
       "      <th>zs</th>\n",
       "      <th>zt</th>\n",
       "      <th>zu</th>\n",
       "      <th>zv</th>\n",
       "      <th>zw</th>\n",
       "      <th>zx</th>\n",
       "      <th>zy</th>\n",
       "      <th>zz</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.416603</td>\n",
       "      <td>0.723617</td>\n",
       "      <td>0.415377</td>\n",
       "      <td>-0.680052</td>\n",
       "      <td>-0.972643</td>\n",
       "      <td>-0.650074</td>\n",
       "      <td>-0.396859</td>\n",
       "      <td>-0.940650</td>\n",
       "      <td>-0.862312</td>\n",
       "      <td>0.839374</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.440917</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.117530</td>\n",
       "      <td>0.758281</td>\n",
       "      <td>-0.133773</td>\n",
       "      <td>-0.331169</td>\n",
       "      <td>-0.657555</td>\n",
       "      <td>-0.098976</td>\n",
       "      <td>-0.824004</td>\n",
       "      <td>-0.613466</td>\n",
       "      <td>-0.664787</td>\n",
       "      <td>-0.322064</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.335126</td>\n",
       "      <td>-0.443883</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.247707</td>\n",
       "      <td>-0.426907</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>-0.324927</td>\n",
       "      <td>-0.585502</td>\n",
       "      <td>-1.236100</td>\n",
       "      <td>1.883928</td>\n",
       "      <td>-0.210752</td>\n",
       "      <td>-0.116468</td>\n",
       "      <td>-0.431933</td>\n",
       "      <td>-0.028292</td>\n",
       "      <td>0.358536</td>\n",
       "      <td>0.852603</td>\n",
       "      <td>...</td>\n",
       "      <td>0.710665</td>\n",
       "      <td>1.221814</td>\n",
       "      <td>2.202849</td>\n",
       "      <td>2.650908</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>2.054142</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.646775</td>\n",
       "      <td>-0.332511</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>-1.079048</td>\n",
       "      <td>0.964454</td>\n",
       "      <td>0.604140</td>\n",
       "      <td>-0.772365</td>\n",
       "      <td>-0.412629</td>\n",
       "      <td>-0.473809</td>\n",
       "      <td>-0.162890</td>\n",
       "      <td>-0.934685</td>\n",
       "      <td>-0.875055</td>\n",
       "      <td>-1.127505</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.453567</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>1.417506</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>-1.161672</td>\n",
       "      <td>-1.480578</td>\n",
       "      <td>1.661224</td>\n",
       "      <td>-0.693418</td>\n",
       "      <td>0.423000</td>\n",
       "      <td>-0.342397</td>\n",
       "      <td>-0.757856</td>\n",
       "      <td>4.226816</td>\n",
       "      <td>1.265663</td>\n",
       "      <td>-1.002905</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.412305</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.479915</td>\n",
       "      <td>-0.069664</td>\n",
       "      <td>-1.016562</td>\n",
       "      <td>-0.317783</td>\n",
       "      <td>-0.651425</td>\n",
       "      <td>-0.889001</td>\n",
       "      <td>-0.865498</td>\n",
       "      <td>-0.601891</td>\n",
       "      <td>-0.913917</td>\n",
       "      <td>-0.876159</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.089304</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.433825</td>\n",
       "      <td>0.414767</td>\n",
       "      <td>-0.404073</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.052278</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>-0.418687</td>\n",
       "      <td>-0.630830</td>\n",
       "      <td>-0.256767</td>\n",
       "      <td>0.941374</td>\n",
       "      <td>-0.465277</td>\n",
       "      <td>0.938462</td>\n",
       "      <td>-0.617458</td>\n",
       "      <td>0.123963</td>\n",
       "      <td>0.615956</td>\n",
       "      <td>1.579467</td>\n",
       "      <td>...</td>\n",
       "      <td>2.391176</td>\n",
       "      <td>0.508124</td>\n",
       "      <td>1.453344</td>\n",
       "      <td>2.811721</td>\n",
       "      <td>1.970152</td>\n",
       "      <td>1.932453</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>1.260585</td>\n",
       "      <td>-0.405569</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.084962</td>\n",
       "      <td>-0.118204</td>\n",
       "      <td>0.369775</td>\n",
       "      <td>-0.562898</td>\n",
       "      <td>0.821575</td>\n",
       "      <td>-0.558084</td>\n",
       "      <td>0.326624</td>\n",
       "      <td>-0.426652</td>\n",
       "      <td>0.237723</td>\n",
       "      <td>-0.814417</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>0.051786</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.450275</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.375679</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.868991</td>\n",
       "      <td>1.049677</td>\n",
       "      <td>0.771618</td>\n",
       "      <td>-0.119401</td>\n",
       "      <td>-0.118935</td>\n",
       "      <td>0.867179</td>\n",
       "      <td>-0.414981</td>\n",
       "      <td>-0.353783</td>\n",
       "      <td>-0.506497</td>\n",
       "      <td>-0.346314</td>\n",
       "      <td>...</td>\n",
       "      <td>0.986613</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.438459</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.003247</td>\n",
       "      <td>1.252699</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.584534</td>\n",
       "      <td>-0.009742</td>\n",
       "      <td>-0.342071</td>\n",
       "      <td>-0.746197</td>\n",
       "      <td>-0.603540</td>\n",
       "      <td>-0.743240</td>\n",
       "      <td>-0.442350</td>\n",
       "      <td>-0.324134</td>\n",
       "      <td>-0.865154</td>\n",
       "      <td>-1.005620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.463294</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>2.072618</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>4.002845</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.160333</td>\n",
       "      <td>-0.511994</td>\n",
       "      <td>1.068892</td>\n",
       "      <td>0.388698</td>\n",
       "      <td>1.337229</td>\n",
       "      <td>-0.555364</td>\n",
       "      <td>0.504589</td>\n",
       "      <td>0.818948</td>\n",
       "      <td>-0.459016</td>\n",
       "      <td>-0.896193</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.296699</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>-0.606709</td>\n",
       "      <td>-0.789521</td>\n",
       "      <td>-0.789697</td>\n",
       "      <td>1.408430</td>\n",
       "      <td>0.106228</td>\n",
       "      <td>0.866211</td>\n",
       "      <td>-0.563853</td>\n",
       "      <td>0.438377</td>\n",
       "      <td>0.297419</td>\n",
       "      <td>1.244996</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308789</td>\n",
       "      <td>1.839215</td>\n",
       "      <td>3.916812</td>\n",
       "      <td>2.721060</td>\n",
       "      <td>1.025801</td>\n",
       "      <td>4.726237</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.295595</td>\n",
       "      <td>-0.384469</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>-0.731493</td>\n",
       "      <td>-1.071353</td>\n",
       "      <td>-0.770802</td>\n",
       "      <td>0.947001</td>\n",
       "      <td>-0.165415</td>\n",
       "      <td>1.357766</td>\n",
       "      <td>0.175381</td>\n",
       "      <td>0.290463</td>\n",
       "      <td>0.608707</td>\n",
       "      <td>3.327363</td>\n",
       "      <td>...</td>\n",
       "      <td>1.707829</td>\n",
       "      <td>1.045791</td>\n",
       "      <td>1.277605</td>\n",
       "      <td>1.747543</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>1.939860</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>2.829463</td>\n",
       "      <td>-0.237246</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.374901</td>\n",
       "      <td>0.791534</td>\n",
       "      <td>-0.884804</td>\n",
       "      <td>-0.102002</td>\n",
       "      <td>-0.337757</td>\n",
       "      <td>-0.562036</td>\n",
       "      <td>-0.732851</td>\n",
       "      <td>2.284796</td>\n",
       "      <td>-0.508282</td>\n",
       "      <td>-0.707804</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.365732</td>\n",
       "      <td>1.137320</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>1.633112</td>\n",
       "      <td>-0.179523</td>\n",
       "      <td>-0.422848</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.471186</td>\n",
       "      <td>0.405905</td>\n",
       "      <td>0.773257</td>\n",
       "      <td>-0.494617</td>\n",
       "      <td>0.056666</td>\n",
       "      <td>-0.478816</td>\n",
       "      <td>-0.112098</td>\n",
       "      <td>0.779845</td>\n",
       "      <td>-0.426728</td>\n",
       "      <td>-0.742607</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.422474</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.398910</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>-0.130406</td>\n",
       "      <td>-0.434458</td>\n",
       "      <td>-0.906149</td>\n",
       "      <td>2.342299</td>\n",
       "      <td>-0.076853</td>\n",
       "      <td>1.574421</td>\n",
       "      <td>-0.336641</td>\n",
       "      <td>0.798047</td>\n",
       "      <td>0.621722</td>\n",
       "      <td>1.576881</td>\n",
       "      <td>...</td>\n",
       "      <td>2.400734</td>\n",
       "      <td>4.550250</td>\n",
       "      <td>1.459472</td>\n",
       "      <td>1.567856</td>\n",
       "      <td>3.107112</td>\n",
       "      <td>1.668014</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.020082</td>\n",
       "      <td>-0.381980</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.472019</td>\n",
       "      <td>0.478082</td>\n",
       "      <td>-0.954979</td>\n",
       "      <td>1.193716</td>\n",
       "      <td>-0.154661</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>-0.534479</td>\n",
       "      <td>-0.162266</td>\n",
       "      <td>-0.109115</td>\n",
       "      <td>-0.501195</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>1.575155</td>\n",
       "      <td>-0.369320</td>\n",
       "      <td>-0.414223</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.262845</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.388120</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.212233</td>\n",
       "      <td>-0.389558</td>\n",
       "      <td>-1.011961</td>\n",
       "      <td>1.271539</td>\n",
       "      <td>-0.138326</td>\n",
       "      <td>0.496216</td>\n",
       "      <td>-0.560573</td>\n",
       "      <td>0.164388</td>\n",
       "      <td>0.700111</td>\n",
       "      <td>1.400998</td>\n",
       "      <td>...</td>\n",
       "      <td>1.340835</td>\n",
       "      <td>0.147865</td>\n",
       "      <td>2.372168</td>\n",
       "      <td>2.197582</td>\n",
       "      <td>1.164065</td>\n",
       "      <td>0.800858</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.648691</td>\n",
       "      <td>-0.392296</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.242201</td>\n",
       "      <td>-0.034972</td>\n",
       "      <td>-0.869167</td>\n",
       "      <td>-0.780145</td>\n",
       "      <td>-1.070022</td>\n",
       "      <td>-0.594381</td>\n",
       "      <td>-0.658763</td>\n",
       "      <td>-0.822466</td>\n",
       "      <td>-1.079186</td>\n",
       "      <td>1.816759</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.463294</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.142577</td>\n",
       "      <td>0.238313</td>\n",
       "      <td>0.939125</td>\n",
       "      <td>1.550963</td>\n",
       "      <td>0.998713</td>\n",
       "      <td>3.123989</td>\n",
       "      <td>1.689148</td>\n",
       "      <td>0.145041</td>\n",
       "      <td>2.816118</td>\n",
       "      <td>0.959008</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.404731</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.362485</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.146276</td>\n",
       "      <td>1.347472</td>\n",
       "      <td>1.809440</td>\n",
       "      <td>-0.025890</td>\n",
       "      <td>2.605557</td>\n",
       "      <td>2.131831</td>\n",
       "      <td>1.098815</td>\n",
       "      <td>2.252985</td>\n",
       "      <td>1.173653</td>\n",
       "      <td>0.033387</td>\n",
       "      <td>...</td>\n",
       "      <td>0.750742</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.442289</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.060865</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>-0.701773</td>\n",
       "      <td>-0.346031</td>\n",
       "      <td>-0.596840</td>\n",
       "      <td>-0.646411</td>\n",
       "      <td>-0.335351</td>\n",
       "      <td>-0.608165</td>\n",
       "      <td>-0.343347</td>\n",
       "      <td>-0.257337</td>\n",
       "      <td>-0.808056</td>\n",
       "      <td>-0.919314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.463294</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>1.196140</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.984902</td>\n",
       "      <td>-0.627283</td>\n",
       "      <td>1.240644</td>\n",
       "      <td>-0.734982</td>\n",
       "      <td>1.977759</td>\n",
       "      <td>1.398694</td>\n",
       "      <td>1.333197</td>\n",
       "      <td>0.697388</td>\n",
       "      <td>1.197408</td>\n",
       "      <td>0.442704</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.463294</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>-0.192772</td>\n",
       "      <td>-1.924731</td>\n",
       "      <td>-0.985014</td>\n",
       "      <td>2.818095</td>\n",
       "      <td>-0.494709</td>\n",
       "      <td>-0.316830</td>\n",
       "      <td>-0.414999</td>\n",
       "      <td>2.220395</td>\n",
       "      <td>1.315473</td>\n",
       "      <td>0.634306</td>\n",
       "      <td>...</td>\n",
       "      <td>3.623933</td>\n",
       "      <td>2.360210</td>\n",
       "      <td>2.243761</td>\n",
       "      <td>2.817723</td>\n",
       "      <td>6.114231</td>\n",
       "      <td>1.636106</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>1.978749</td>\n",
       "      <td>-0.319590</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.513215</td>\n",
       "      <td>0.665206</td>\n",
       "      <td>-0.711591</td>\n",
       "      <td>-0.948580</td>\n",
       "      <td>-1.078311</td>\n",
       "      <td>-0.186731</td>\n",
       "      <td>-0.582831</td>\n",
       "      <td>-0.643428</td>\n",
       "      <td>-0.987616</td>\n",
       "      <td>0.729532</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>0.580440</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.463294</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.246717</td>\n",
       "      <td>1.118436</td>\n",
       "      <td>1.935927</td>\n",
       "      <td>-0.542480</td>\n",
       "      <td>1.692222</td>\n",
       "      <td>2.108672</td>\n",
       "      <td>1.623921</td>\n",
       "      <td>0.497574</td>\n",
       "      <td>0.970406</td>\n",
       "      <td>-0.178641</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.048279</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.457968</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.431399</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.501025</td>\n",
       "      <td>0.004268</td>\n",
       "      <td>-0.115630</td>\n",
       "      <td>-0.899037</td>\n",
       "      <td>-0.395884</td>\n",
       "      <td>-0.833529</td>\n",
       "      <td>-0.436720</td>\n",
       "      <td>-0.777164</td>\n",
       "      <td>-0.914637</td>\n",
       "      <td>-0.769673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.153069</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.405314</td>\n",
       "      <td>-0.437966</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.108000</td>\n",
       "      <td>1.311426</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>-0.276518</td>\n",
       "      <td>-1.322234</td>\n",
       "      <td>-1.070971</td>\n",
       "      <td>2.328206</td>\n",
       "      <td>0.991954</td>\n",
       "      <td>0.615134</td>\n",
       "      <td>-0.273846</td>\n",
       "      <td>0.051737</td>\n",
       "      <td>0.552695</td>\n",
       "      <td>1.344199</td>\n",
       "      <td>...</td>\n",
       "      <td>2.558359</td>\n",
       "      <td>1.629242</td>\n",
       "      <td>2.645221</td>\n",
       "      <td>1.626261</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>1.301936</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.454577</td>\n",
       "      <td>-0.353524</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.604770</td>\n",
       "      <td>1.287324</td>\n",
       "      <td>-1.151780</td>\n",
       "      <td>-0.852843</td>\n",
       "      <td>-0.865168</td>\n",
       "      <td>-0.940952</td>\n",
       "      <td>-0.934909</td>\n",
       "      <td>-0.803829</td>\n",
       "      <td>-0.899195</td>\n",
       "      <td>-0.929758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.165163</td>\n",
       "      <td>-0.012454</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.440297</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.429735</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.180746</td>\n",
       "      <td>0.165480</td>\n",
       "      <td>-0.930095</td>\n",
       "      <td>1.196454</td>\n",
       "      <td>-0.832147</td>\n",
       "      <td>-0.435106</td>\n",
       "      <td>-0.519808</td>\n",
       "      <td>-1.075150</td>\n",
       "      <td>-0.946336</td>\n",
       "      <td>0.919274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.338120</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.374863</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>-1.159419</td>\n",
       "      <td>-1.146734</td>\n",
       "      <td>-0.422552</td>\n",
       "      <td>1.926975</td>\n",
       "      <td>-0.208716</td>\n",
       "      <td>0.397134</td>\n",
       "      <td>-0.501818</td>\n",
       "      <td>-0.673083</td>\n",
       "      <td>1.334422</td>\n",
       "      <td>0.804510</td>\n",
       "      <td>...</td>\n",
       "      <td>0.210570</td>\n",
       "      <td>1.569709</td>\n",
       "      <td>2.032059</td>\n",
       "      <td>2.326388</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>2.066517</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.009764</td>\n",
       "      <td>-0.356287</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.615177</td>\n",
       "      <td>0.894673</td>\n",
       "      <td>-1.055522</td>\n",
       "      <td>-0.412669</td>\n",
       "      <td>-0.708049</td>\n",
       "      <td>-0.708727</td>\n",
       "      <td>-0.890473</td>\n",
       "      <td>-0.669775</td>\n",
       "      <td>-0.350717</td>\n",
       "      <td>-0.856989</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008529</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.450276</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.137404</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-1.155538</td>\n",
       "      <td>-1.177980</td>\n",
       "      <td>0.149723</td>\n",
       "      <td>-0.939670</td>\n",
       "      <td>-0.947473</td>\n",
       "      <td>-0.979279</td>\n",
       "      <td>-0.525395</td>\n",
       "      <td>-1.022689</td>\n",
       "      <td>-0.708600</td>\n",
       "      <td>-1.037747</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.118393</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.458798</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.287506</td>\n",
       "      <td>3.586525</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>-1.251780</td>\n",
       "      <td>-1.506645</td>\n",
       "      <td>1.495224</td>\n",
       "      <td>-0.806573</td>\n",
       "      <td>-0.440125</td>\n",
       "      <td>-0.607518</td>\n",
       "      <td>-0.883155</td>\n",
       "      <td>0.254104</td>\n",
       "      <td>-0.557941</td>\n",
       "      <td>-1.093365</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.068981</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.382009</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.398772</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>5.738529</td>\n",
       "      <td>-0.227696</td>\n",
       "      <td>-0.032461</td>\n",
       "      <td>-0.799340</td>\n",
       "      <td>-0.937770</td>\n",
       "      <td>-1.134917</td>\n",
       "      <td>0.093631</td>\n",
       "      <td>-0.972846</td>\n",
       "      <td>-1.024799</td>\n",
       "      <td>1.887240</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.438511</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.700354</td>\n",
       "      <td>2.502460</td>\n",
       "      <td>0.689884</td>\n",
       "      <td>-0.317027</td>\n",
       "      <td>0.857285</td>\n",
       "      <td>0.392314</td>\n",
       "      <td>4.007899</td>\n",
       "      <td>2.058633</td>\n",
       "      <td>0.563854</td>\n",
       "      <td>0.595397</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.316885</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>3.862169</td>\n",
       "      <td>0.426806</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.077582</td>\n",
       "      <td>1.155373</td>\n",
       "      <td>-0.274041</td>\n",
       "      <td>-0.741659</td>\n",
       "      <td>-0.670956</td>\n",
       "      <td>-0.508790</td>\n",
       "      <td>-0.566428</td>\n",
       "      <td>-0.633717</td>\n",
       "      <td>-0.206734</td>\n",
       "      <td>-0.985400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.604521</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.435347</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.114544</td>\n",
       "      <td>2.142488</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.794133</td>\n",
       "      <td>-0.444301</td>\n",
       "      <td>2.247267</td>\n",
       "      <td>-0.087692</td>\n",
       "      <td>1.191238</td>\n",
       "      <td>0.305072</td>\n",
       "      <td>1.907106</td>\n",
       "      <td>0.162007</td>\n",
       "      <td>1.267668</td>\n",
       "      <td>-0.307942</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.396440</td>\n",
       "      <td>-0.445687</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.367933</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.416050</td>\n",
       "      <td>-0.443136</td>\n",
       "      <td>-1.126154</td>\n",
       "      <td>-1.004159</td>\n",
       "      <td>-0.761529</td>\n",
       "      <td>-0.290453</td>\n",
       "      <td>-0.280356</td>\n",
       "      <td>0.327604</td>\n",
       "      <td>-1.036307</td>\n",
       "      <td>-0.160437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.463294</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.193898</td>\n",
       "      <td>1.394390</td>\n",
       "      <td>1.802844</td>\n",
       "      <td>-0.143289</td>\n",
       "      <td>2.903203</td>\n",
       "      <td>2.253254</td>\n",
       "      <td>3.313789</td>\n",
       "      <td>0.262632</td>\n",
       "      <td>2.306369</td>\n",
       "      <td>0.674188</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.450891</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.347439</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.226289</td>\n",
       "      <td>-0.403631</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.126759</td>\n",
       "      <td>0.752618</td>\n",
       "      <td>-0.034805</td>\n",
       "      <td>-0.964298</td>\n",
       "      <td>-0.234578</td>\n",
       "      <td>-0.728986</td>\n",
       "      <td>-0.152700</td>\n",
       "      <td>-1.052465</td>\n",
       "      <td>-0.487453</td>\n",
       "      <td>-0.837256</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.443629</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>1.167833</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>-1.057919</td>\n",
       "      <td>-1.817415</td>\n",
       "      <td>1.542611</td>\n",
       "      <td>-0.882975</td>\n",
       "      <td>-0.033065</td>\n",
       "      <td>-0.566655</td>\n",
       "      <td>-0.518209</td>\n",
       "      <td>-0.494384</td>\n",
       "      <td>-0.298410</td>\n",
       "      <td>-1.049630</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.438052</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.224329</td>\n",
       "      <td>1.228361</td>\n",
       "      <td>-1.005215</td>\n",
       "      <td>-0.722581</td>\n",
       "      <td>-0.235760</td>\n",
       "      <td>1.367405</td>\n",
       "      <td>-0.155398</td>\n",
       "      <td>0.345793</td>\n",
       "      <td>-0.062058</td>\n",
       "      <td>-0.527997</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.431079</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.295781</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>1.863188</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>-0.353150</td>\n",
       "      <td>0.270343</td>\n",
       "      <td>-0.123415</td>\n",
       "      <td>0.290289</td>\n",
       "      <td>-0.182721</td>\n",
       "      <td>0.305107</td>\n",
       "      <td>-0.241229</td>\n",
       "      <td>-0.361666</td>\n",
       "      <td>-0.619510</td>\n",
       "      <td>-0.720389</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.360794</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.369424</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>1.910167</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.164584</td>\n",
       "      <td>-0.233779</td>\n",
       "      <td>-1.025309</td>\n",
       "      <td>-0.628988</td>\n",
       "      <td>-0.648573</td>\n",
       "      <td>-0.874887</td>\n",
       "      <td>-0.861259</td>\n",
       "      <td>-0.740983</td>\n",
       "      <td>-0.698752</td>\n",
       "      <td>-0.662592</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.455357</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.390016</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.094906</td>\n",
       "      <td>-0.633519</td>\n",
       "      <td>-0.955744</td>\n",
       "      <td>-0.672833</td>\n",
       "      <td>-0.621057</td>\n",
       "      <td>-0.515545</td>\n",
       "      <td>-0.666140</td>\n",
       "      <td>-0.770338</td>\n",
       "      <td>-0.678864</td>\n",
       "      <td>-0.891992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288399</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.436296</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.035576</td>\n",
       "      <td>-0.372853</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>-0.987807</td>\n",
       "      <td>-1.214064</td>\n",
       "      <td>0.728589</td>\n",
       "      <td>-0.865292</td>\n",
       "      <td>-0.004036</td>\n",
       "      <td>-0.655207</td>\n",
       "      <td>-0.200017</td>\n",
       "      <td>-0.580103</td>\n",
       "      <td>-0.150701</td>\n",
       "      <td>-0.958778</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.424814</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.269688</td>\n",
       "      <td>-0.777473</td>\n",
       "      <td>-0.689605</td>\n",
       "      <td>-0.490897</td>\n",
       "      <td>-0.706742</td>\n",
       "      <td>-0.678872</td>\n",
       "      <td>-0.786850</td>\n",
       "      <td>-0.613414</td>\n",
       "      <td>-0.711014</td>\n",
       "      <td>-0.783692</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>2.765009</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.447848</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.105443</td>\n",
       "      <td>-0.421992</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.466689</td>\n",
       "      <td>-1.503044</td>\n",
       "      <td>-0.693881</td>\n",
       "      <td>-0.814459</td>\n",
       "      <td>-1.121628</td>\n",
       "      <td>-1.152407</td>\n",
       "      <td>-0.486623</td>\n",
       "      <td>-1.151393</td>\n",
       "      <td>-0.841759</td>\n",
       "      <td>0.421042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.449987</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.367547</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>-0.212168</td>\n",
       "      <td>-0.634121</td>\n",
       "      <td>1.045504</td>\n",
       "      <td>0.751405</td>\n",
       "      <td>0.244624</td>\n",
       "      <td>-0.215240</td>\n",
       "      <td>-0.173632</td>\n",
       "      <td>1.172316</td>\n",
       "      <td>0.148032</td>\n",
       "      <td>-0.747254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.325595</td>\n",
       "      <td>-0.406223</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.784552</td>\n",
       "      <td>0.085316</td>\n",
       "      <td>1.811304</td>\n",
       "      <td>-0.292830</td>\n",
       "      <td>2.393265</td>\n",
       "      <td>0.474916</td>\n",
       "      <td>1.434685</td>\n",
       "      <td>-0.079431</td>\n",
       "      <td>2.310223</td>\n",
       "      <td>-0.341951</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.425060</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.579943</td>\n",
       "      <td>-0.034239</td>\n",
       "      <td>-0.521261</td>\n",
       "      <td>-0.371006</td>\n",
       "      <td>-0.761229</td>\n",
       "      <td>-1.187587</td>\n",
       "      <td>0.141655</td>\n",
       "      <td>-0.488587</td>\n",
       "      <td>-0.955258</td>\n",
       "      <td>0.321844</td>\n",
       "      <td>...</td>\n",
       "      <td>2.587434</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.437882</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>0.463046</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.328694</td>\n",
       "      <td>1.110413</td>\n",
       "      <td>1.279322</td>\n",
       "      <td>0.354841</td>\n",
       "      <td>1.417059</td>\n",
       "      <td>1.284397</td>\n",
       "      <td>1.198743</td>\n",
       "      <td>0.457007</td>\n",
       "      <td>0.988000</td>\n",
       "      <td>-0.289014</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.054186</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.427576</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.164002</td>\n",
       "      <td>-0.452290</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.350972</td>\n",
       "      <td>0.777173</td>\n",
       "      <td>-0.726662</td>\n",
       "      <td>-0.223466</td>\n",
       "      <td>-1.015891</td>\n",
       "      <td>-0.926110</td>\n",
       "      <td>0.527070</td>\n",
       "      <td>-0.789458</td>\n",
       "      <td>-0.875931</td>\n",
       "      <td>0.510054</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.543097</td>\n",
       "      <td>-0.498310</td>\n",
       "      <td>-0.428048</td>\n",
       "      <td>-0.448057</td>\n",
       "      <td>-0.281763</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.275911</td>\n",
       "      <td>-0.448826</td>\n",
       "      <td>-0.392514</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>54 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          $$        $_        $a        $b        $c        $d        $e  \\\n",
       "17  0.416603  0.723617  0.415377 -0.680052 -0.972643 -0.650074 -0.396859   \n",
       "5   1.117530  0.758281 -0.133773 -0.331169 -0.657555 -0.098976 -0.824004   \n",
       "33 -0.324927 -0.585502 -1.236100  1.883928 -0.210752 -0.116468 -0.431933   \n",
       "48 -1.079048  0.964454  0.604140 -0.772365 -0.412629 -0.473809 -0.162890   \n",
       "58 -1.161672 -1.480578  1.661224 -0.693418  0.423000 -0.342397 -0.757856   \n",
       "2   0.479915 -0.069664 -1.016562 -0.317783 -0.651425 -0.889001 -0.865498   \n",
       "36 -0.418687 -0.630830 -0.256767  0.941374 -0.465277  0.938462 -0.617458   \n",
       "54  0.084962 -0.118204  0.369775 -0.562898  0.821575 -0.558084  0.326624   \n",
       "46 -0.868991  1.049677  0.771618 -0.119401 -0.118935  0.867179 -0.414981   \n",
       "51 -0.584534 -0.009742 -0.342071 -0.746197 -0.603540 -0.743240 -0.442350   \n",
       "59  0.160333 -0.511994  1.068892  0.388698  1.337229 -0.555364  0.504589   \n",
       "35 -0.606709 -0.789521 -0.789697  1.408430  0.106228  0.866211 -0.563853   \n",
       "32 -0.731493 -1.071353 -0.770802  0.947001 -0.165415  1.357766  0.175381   \n",
       "10  0.374901  0.791534 -0.884804 -0.102002 -0.337757 -0.562036 -0.732851   \n",
       "56  0.471186  0.405905  0.773257 -0.494617  0.056666 -0.478816 -0.112098   \n",
       "39 -0.130406 -0.434458 -0.906149  2.342299 -0.076853  1.574421 -0.336641   \n",
       "8   0.472019  0.478082 -0.954979  1.193716 -0.154661  0.017062 -0.534479   \n",
       "40  0.212233 -0.389558 -1.011961  1.271539 -0.138326  0.496216 -0.560573   \n",
       "19 -0.242201 -0.034972 -0.869167 -0.780145 -1.070022 -0.594381 -0.658763   \n",
       "31  0.142577  0.238313  0.939125  1.550963  0.998713  3.123989  1.689148   \n",
       "28  0.146276  1.347472  1.809440 -0.025890  2.605557  2.131831  1.098815   \n",
       "49 -0.701773 -0.346031 -0.596840 -0.646411 -0.335351 -0.608165 -0.343347   \n",
       "30 -0.984902 -0.627283  1.240644 -0.734982  1.977759  1.398694  1.333197   \n",
       "38 -0.192772 -1.924731 -0.985014  2.818095 -0.494709 -0.316830 -0.414999   \n",
       "18 -0.513215  0.665206 -0.711591 -0.948580 -1.078311 -0.186731 -0.582831   \n",
       "29 -0.246717  1.118436  1.935927 -0.542480  1.692222  2.108672  1.623921   \n",
       "43 -0.501025  0.004268 -0.115630 -0.899037 -0.395884 -0.833529 -0.436720   \n",
       "34 -0.276518 -1.322234 -1.070971  2.328206  0.991954  0.615134 -0.273846   \n",
       "0   1.604770  1.287324 -1.151780 -0.852843 -0.865168 -0.940952 -0.934909   \n",
       "20  0.180746  0.165480 -0.930095  1.196454 -0.832147 -0.435106 -0.519808   \n",
       "37 -1.159419 -1.146734 -0.422552  1.926975 -0.208716  0.397134 -0.501818   \n",
       "3   0.615177  0.894673 -1.055522 -0.412669 -0.708049 -0.708727 -0.890473   \n",
       "47 -1.155538 -1.177980  0.149723 -0.939670 -0.947473 -0.979279 -0.525395   \n",
       "57 -1.251780 -1.506645  1.495224 -0.806573 -0.440125 -0.607518 -0.883155   \n",
       "13  5.738529 -0.227696 -0.032461 -0.799340 -0.937770 -1.134917  0.093631   \n",
       "22  0.700354  2.502460  0.689884 -0.317027  0.857285  0.392314  4.007899   \n",
       "44  0.077582  1.155373 -0.274041 -0.741659 -0.670956 -0.508790 -0.566428   \n",
       "24 -0.794133 -0.444301  2.247267 -0.087692  1.191238  0.305072  1.907106   \n",
       "21  0.416050 -0.443136 -1.126154 -1.004159 -0.761529 -0.290453 -0.280356   \n",
       "23  0.193898  1.394390  1.802844 -0.143289  2.903203  2.253254  3.313789   \n",
       "45  0.126759  0.752618 -0.034805 -0.964298 -0.234578 -0.728986 -0.152700   \n",
       "53 -1.057919 -1.817415  1.542611 -0.882975 -0.033065 -0.566655 -0.518209   \n",
       "9   1.224329  1.228361 -1.005215 -0.722581 -0.235760  1.367405 -0.155398   \n",
       "50 -0.353150  0.270343 -0.123415  0.290289 -0.182721  0.305107 -0.241229   \n",
       "7   0.164584 -0.233779 -1.025309 -0.628988 -0.648573 -0.874887 -0.861259   \n",
       "1   0.094906 -0.633519 -0.955744 -0.672833 -0.621057 -0.515545 -0.666140   \n",
       "55 -0.987807 -1.214064  0.728589 -0.865292 -0.004036 -0.655207 -0.200017   \n",
       "6  -0.269688 -0.777473 -0.689605 -0.490897 -0.706742 -0.678872 -0.786850   \n",
       "11 -0.466689 -1.503044 -0.693881 -0.814459 -1.121628 -1.152407 -0.486623   \n",
       "52 -0.212168 -0.634121  1.045504  0.751405  0.244624 -0.215240 -0.173632   \n",
       "27 -0.784552  0.085316  1.811304 -0.292830  2.393265  0.474916  1.434685   \n",
       "14  0.579943 -0.034239 -0.521261 -0.371006 -0.761229 -1.187587  0.141655   \n",
       "25 -0.328694  1.110413  1.279322  0.354841  1.417059  1.284397  1.198743   \n",
       "15  0.350972  0.777173 -0.726662 -0.223466 -1.015891 -0.926110  0.527070   \n",
       "\n",
       "          $f        $g        $h  ...         zr        zs        zt  \\\n",
       "17 -0.940650 -0.862312  0.839374  ...  -0.543097 -0.498310 -0.428048   \n",
       "5  -0.613466 -0.664787 -0.322064  ...  -0.543097 -0.498310 -0.335126   \n",
       "33 -0.028292  0.358536  0.852603  ...   0.710665  1.221814  2.202849   \n",
       "48 -0.934685 -0.875055 -1.127505  ...  -0.543097 -0.498310 -0.428048   \n",
       "58  4.226816  1.265663 -1.002905  ...  -0.543097 -0.498310 -0.428048   \n",
       "2  -0.601891 -0.913917 -0.876159  ...  -0.089304 -0.498310 -0.428048   \n",
       "36  0.123963  0.615956  1.579467  ...   2.391176  0.508124  1.453344   \n",
       "54 -0.426652  0.237723 -0.814417  ...  -0.543097  0.051786 -0.428048   \n",
       "46 -0.353783 -0.506497 -0.346314  ...   0.986613 -0.498310 -0.428048   \n",
       "51 -0.324134 -0.865154 -1.005620  ...  -0.543097 -0.498310 -0.428048   \n",
       "59  0.818948 -0.459016 -0.896193  ...  -0.543097 -0.498310 -0.428048   \n",
       "35  0.438377  0.297419  1.244996  ...   0.308789  1.839215  3.916812   \n",
       "32  0.290463  0.608707  3.327363  ...   1.707829  1.045791  1.277605   \n",
       "10  2.284796 -0.508282 -0.707804  ...  -0.543097 -0.498310 -0.428048   \n",
       "56  0.779845 -0.426728 -0.742607  ...  -0.543097 -0.498310 -0.428048   \n",
       "39  0.798047  0.621722  1.576881  ...   2.400734  4.550250  1.459472   \n",
       "8  -0.162266 -0.109115 -0.501195  ...  -0.543097  1.575155 -0.369320   \n",
       "40  0.164388  0.700111  1.400998  ...   1.340835  0.147865  2.372168   \n",
       "19 -0.822466 -1.079186  1.816759  ...  -0.543097 -0.498310 -0.428048   \n",
       "31  0.145041  2.816118  0.959008  ...  -0.543097 -0.498310 -0.428048   \n",
       "28  2.252985  1.173653  0.033387  ...   0.750742 -0.498310 -0.428048   \n",
       "49 -0.257337 -0.808056 -0.919314  ...  -0.543097 -0.498310 -0.428048   \n",
       "30  0.697388  1.197408  0.442704  ...  -0.543097 -0.498310 -0.428048   \n",
       "38  2.220395  1.315473  0.634306  ...   3.623933  2.360210  2.243761   \n",
       "18 -0.643428 -0.987616  0.729532  ...  -0.543097  0.580440 -0.428048   \n",
       "29  0.497574  0.970406 -0.178641  ...  -0.543097 -0.048279 -0.428048   \n",
       "43 -0.777164 -0.914637 -0.769673  ...  -0.153069 -0.498310 -0.405314   \n",
       "34  0.051737  0.552695  1.344199  ...   2.558359  1.629242  2.645221   \n",
       "0  -0.803829 -0.899195 -0.929758  ...   0.165163 -0.012454 -0.428048   \n",
       "20 -1.075150 -0.946336  0.919274  ...  -0.543097 -0.498310 -0.428048   \n",
       "37 -0.673083  1.334422  0.804510  ...   0.210570  1.569709  2.032059   \n",
       "3  -0.669775 -0.350717 -0.856989  ...  -0.008529 -0.498310 -0.428048   \n",
       "47 -1.022689 -0.708600 -1.037747  ...  -0.543097 -0.118393 -0.428048   \n",
       "57  0.254104 -0.557941 -1.093365  ...  -0.543097 -0.068981 -0.428048   \n",
       "13 -0.972846 -1.024799  1.887240  ...  -0.543097 -0.498310 -0.428048   \n",
       "22  2.058633  0.563854  0.595397  ...  -0.543097 -0.498310 -0.428048   \n",
       "44 -0.633717 -0.206734 -0.985400  ...   0.604521 -0.498310 -0.428048   \n",
       "24  0.162007  1.267668 -0.307942  ...  -0.543097 -0.498310 -0.396440   \n",
       "21  0.327604 -1.036307 -0.160437  ...  -0.543097 -0.498310 -0.428048   \n",
       "23  0.262632  2.306369  0.674188  ...  -0.543097 -0.498310 -0.428048   \n",
       "45 -1.052465 -0.487453 -0.837256  ...  -0.543097 -0.498310 -0.428048   \n",
       "53 -0.494384 -0.298410 -1.049630  ...  -0.543097 -0.498310 -0.428048   \n",
       "9   0.345793 -0.062058 -0.527997  ...  -0.543097 -0.498310 -0.428048   \n",
       "50 -0.361666 -0.619510 -0.720389  ...  -0.543097 -0.498310 -0.428048   \n",
       "7  -0.740983 -0.698752 -0.662592  ...  -0.543097 -0.498310 -0.428048   \n",
       "1  -0.770338 -0.678864 -0.891992  ...   0.288399 -0.498310 -0.428048   \n",
       "55 -0.580103 -0.150701 -0.958778  ...  -0.543097 -0.498310 -0.428048   \n",
       "6  -0.613414 -0.711014 -0.783692  ...  -0.543097  2.765009 -0.428048   \n",
       "11 -1.151393 -0.841759  0.421042  ...  -0.543097 -0.498310 -0.428048   \n",
       "52  1.172316  0.148032 -0.747254  ...  -0.543097 -0.498310 -0.325595   \n",
       "27 -0.079431  2.310223 -0.341951  ...  -0.543097 -0.498310 -0.428048   \n",
       "14 -0.488587 -0.955258  0.321844  ...   2.587434 -0.498310 -0.428048   \n",
       "25  0.457007  0.988000 -0.289014  ...  -0.054186 -0.498310 -0.428048   \n",
       "15 -0.789458 -0.875931  0.510054  ...  -0.543097 -0.498310 -0.428048   \n",
       "\n",
       "          zu        zv        zw        zx        zy        zz  bias  \n",
       "17 -0.440917 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "5  -0.443883 -0.281763 -0.418054 -0.275911  0.247707 -0.426907   1.0  \n",
       "33  2.650908 -0.281763  2.054142 -0.275911  0.646775 -0.332511   1.0  \n",
       "48 -0.453567 -0.281763 -0.418054 -0.275911 -0.448826  1.417506   1.0  \n",
       "58 -0.412305 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "2  -0.433825  0.414767 -0.404073 -0.275911 -0.052278 -0.452290   1.0  \n",
       "36  2.811721  1.970152  1.932453 -0.275911  1.260585 -0.405569   1.0  \n",
       "54 -0.450275 -0.281763 -0.418054 -0.275911 -0.448826 -0.375679   1.0  \n",
       "46 -0.438459 -0.281763 -0.418054 -0.275911 -0.003247  1.252699   1.0  \n",
       "51 -0.463294 -0.281763 -0.418054  2.072618 -0.448826  4.002845   1.0  \n",
       "59 -0.296699 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "35  2.721060  1.025801  4.726237 -0.275911  0.295595 -0.384469   1.0  \n",
       "32  1.747543 -0.281763  1.939860 -0.275911  2.829463 -0.237246   1.0  \n",
       "10 -0.365732  1.137320 -0.418054  1.633112 -0.179523 -0.422848   1.0  \n",
       "56 -0.422474 -0.281763 -0.418054 -0.275911 -0.448826 -0.398910   1.0  \n",
       "39  1.567856  3.107112  1.668014 -0.275911 -0.020082 -0.381980   1.0  \n",
       "8  -0.414223 -0.281763 -0.262845 -0.275911 -0.448826 -0.388120   1.0  \n",
       "40  2.197582  1.164065  0.800858 -0.275911  0.648691 -0.392296   1.0  \n",
       "19 -0.463294 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "31 -0.404731 -0.281763 -0.362485 -0.275911 -0.448826 -0.452290   1.0  \n",
       "28 -0.442289 -0.281763 -0.418054 -0.275911 -0.448826 -0.060865   1.0  \n",
       "49 -0.463294 -0.281763 -0.418054 -0.275911 -0.448826  1.196140   1.0  \n",
       "30 -0.463294 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "38  2.817723  6.114231  1.636106 -0.275911  1.978749 -0.319590   1.0  \n",
       "18 -0.463294 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "29 -0.457968 -0.281763 -0.418054 -0.275911 -0.448826 -0.431399   1.0  \n",
       "43 -0.437966 -0.281763 -0.418054 -0.275911 -0.108000  1.311426   1.0  \n",
       "34  1.626261 -0.281763  1.301936 -0.275911  0.454577 -0.353524   1.0  \n",
       "0  -0.440297 -0.281763 -0.418054 -0.275911 -0.448826 -0.429735   1.0  \n",
       "20 -0.338120 -0.281763 -0.374863 -0.275911 -0.448826 -0.452290   1.0  \n",
       "37  2.326388 -0.281763  2.066517 -0.275911 -0.009764 -0.356287   1.0  \n",
       "3  -0.450276 -0.281763 -0.418054 -0.275911 -0.137404 -0.452290   1.0  \n",
       "47 -0.458798 -0.281763 -0.418054 -0.275911 -0.287506  3.586525   1.0  \n",
       "57 -0.382009 -0.281763 -0.398772 -0.275911 -0.448826 -0.452290   1.0  \n",
       "13 -0.438511 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "22 -0.316885 -0.281763 -0.418054  3.862169  0.426806 -0.452290   1.0  \n",
       "44 -0.435347 -0.281763 -0.418054 -0.275911 -0.114544  2.142488   1.0  \n",
       "24 -0.445687 -0.281763 -0.367933 -0.275911 -0.448826 -0.452290   1.0  \n",
       "21 -0.463294 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "23 -0.450891 -0.281763 -0.347439 -0.275911 -0.226289 -0.403631   1.0  \n",
       "45 -0.443629 -0.281763 -0.418054 -0.275911 -0.448826  1.167833   1.0  \n",
       "53 -0.438052 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "9  -0.431079 -0.281763 -0.295781 -0.275911  1.863188 -0.452290   1.0  \n",
       "50 -0.360794 -0.281763 -0.369424 -0.275911 -0.448826  1.910167   1.0  \n",
       "7  -0.455357 -0.281763 -0.418054 -0.275911 -0.448826 -0.390016   1.0  \n",
       "1  -0.436296 -0.281763 -0.418054 -0.275911  0.035576 -0.372853   1.0  \n",
       "55 -0.424814 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "6  -0.447848 -0.281763 -0.418054 -0.275911  0.105443 -0.421992   1.0  \n",
       "11 -0.449987 -0.281763 -0.367547 -0.275911 -0.448826 -0.452290   1.0  \n",
       "52 -0.406223 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "27 -0.425060 -0.281763 -0.418054 -0.275911 -0.448826 -0.452290   1.0  \n",
       "14 -0.437882 -0.281763 -0.418054 -0.275911  0.463046 -0.452290   1.0  \n",
       "25 -0.427576 -0.281763 -0.418054 -0.275911 -0.164002 -0.452290   1.0  \n",
       "15 -0.448057 -0.281763 -0.418054 -0.275911 -0.448826 -0.392514   1.0  \n",
       "\n",
       "[54 rows x 785 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bias_vector = np.ones([X_train.shape[0], 1])\n",
    "X_train['bias'] = bias_vector\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise weight matrix with small weights\n",
    "\n",
    "np.random.seed(seed=200)\n",
    "\n",
    "W = np.random.randn(X_train.shape[1], len(lb.classes_)) * 0.0001\n",
    "#W = np.zeros([X.shape[1], len(lb.classes_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the dimensions are right. The dot product of a specific row from X_train and the weight matrix W constitutes a forward pass and calculates the score for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(785, 6)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(54, 785)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002759</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>-0.00002</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4        5\n",
       "2 -0.002759  0.001104  0.000341 -0.000792  0.003832 -0.00002"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5:6].dot(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the values for the highest score of the dot product is not the score of the true label. Our aim is to change this by implementing a support vector classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.003832\n",
       "dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5:6].dot(W).max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    0.001104\n",
       "Name: 1, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[5:6].dot(W)[y_train[5:6].argmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: we follow kind of a naive implementation. The aim is to be able to understand what is going on!\n",
    "\n",
    "In order to quantify how good (or how bad) our weight matrix W can predict the data in our training set, we need to implement a loss function. Here we take a go at the hinge loss, which tries to predict the correct class with a margin of at least one to all other classes (or in this case, like presented in Goldberg, to the class which does not equal the true class, but which scores highest). In my understanding, this is a one-vs-one approach (true class vs. class with highest score (but doesn't equal the true class))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiclass_hinge_loss(x, y, W, index):\n",
    "    \"\"\"\n",
    "    Calculates the loss of a single data point by taking the prediction of the correct value and the the prediction of\n",
    "    the value of next highest score, following Crammer and Singer (2001)\n",
    "    :param x: sample point x as a vector\n",
    "    :param y: correct label y for x as a vector\n",
    "    :param W: weight matrix\n",
    "    :param index: column index of data matrix X\n",
    "    :return: loss\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    y_index = y[index].argmax()\n",
    "    y_value = x.dot(W)[y_index]\n",
    "    y_hat_max_value = np.delete(x.dot(W), y_index).max()\n",
    "    #for j in range(0, y.shape[1]):  # in case we wanted to classify against all other classes (one-vs-all) --> currently one-vs-one\n",
    "        #if j == y_index:\n",
    "            #continue\n",
    "    loss += max(0, 1 - (y_value - y_hat_max_value))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With matrix multiplication, we could get all the scores at once. In the following, however, we focus on an approach which takes sample by sample and calculates the loss and the gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = X_train.dot(W)  # simple matrix multiplication to get all scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.007368</td>\n",
       "      <td>-0.005240</td>\n",
       "      <td>-0.004246</td>\n",
       "      <td>-0.006304</td>\n",
       "      <td>0.000809</td>\n",
       "      <td>0.003532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.005714</td>\n",
       "      <td>-0.006824</td>\n",
       "      <td>0.001335</td>\n",
       "      <td>-0.000417</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>-0.000727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.003551</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>-0.001101</td>\n",
       "      <td>-0.000361</td>\n",
       "      <td>-0.000557</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.002507</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.002059</td>\n",
       "      <td>0.000290</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.002088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.000668</td>\n",
       "      <td>-0.000813</td>\n",
       "      <td>0.006170</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>-0.002476</td>\n",
       "      <td>0.000330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.002759</td>\n",
       "      <td>0.001104</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>-0.000792</td>\n",
       "      <td>0.003832</td>\n",
       "      <td>-0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.000503</td>\n",
       "      <td>-0.005084</td>\n",
       "      <td>-0.002883</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>-0.000622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>-0.001155</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.005849</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.004633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>-0.002019</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0.001601</td>\n",
       "      <td>-0.000900</td>\n",
       "      <td>-0.001941</td>\n",
       "      <td>-0.004775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>-0.000868</td>\n",
       "      <td>0.004477</td>\n",
       "      <td>0.001178</td>\n",
       "      <td>0.001421</td>\n",
       "      <td>0.001766</td>\n",
       "      <td>-0.004702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.006010</td>\n",
       "      <td>0.003136</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.003549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.006555</td>\n",
       "      <td>0.003974</td>\n",
       "      <td>-0.000240</td>\n",
       "      <td>0.003947</td>\n",
       "      <td>-0.002288</td>\n",
       "      <td>0.003274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.004159</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>-0.004290</td>\n",
       "      <td>0.001681</td>\n",
       "      <td>-0.004668</td>\n",
       "      <td>-0.000230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000330</td>\n",
       "      <td>0.003582</td>\n",
       "      <td>0.001613</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>-0.002155</td>\n",
       "      <td>-0.000534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>-0.000092</td>\n",
       "      <td>-0.003041</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.001230</td>\n",
       "      <td>0.001610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.004409</td>\n",
       "      <td>-0.003615</td>\n",
       "      <td>-0.001977</td>\n",
       "      <td>-0.002797</td>\n",
       "      <td>-0.004215</td>\n",
       "      <td>0.003713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.004439</td>\n",
       "      <td>-0.003346</td>\n",
       "      <td>-0.002271</td>\n",
       "      <td>-0.001065</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>0.001821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.006360</td>\n",
       "      <td>0.001308</td>\n",
       "      <td>0.001281</td>\n",
       "      <td>0.003900</td>\n",
       "      <td>-0.000179</td>\n",
       "      <td>0.000545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-0.001942</td>\n",
       "      <td>-0.004445</td>\n",
       "      <td>-0.003178</td>\n",
       "      <td>-0.003595</td>\n",
       "      <td>-0.001905</td>\n",
       "      <td>0.001898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>-0.000496</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>-0.002990</td>\n",
       "      <td>0.000607</td>\n",
       "      <td>-0.002641</td>\n",
       "      <td>-0.004012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-0.005982</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.001675</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>-0.002314</td>\n",
       "      <td>-0.003643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.003294</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.001061</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>-0.003271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-0.001233</td>\n",
       "      <td>-0.002927</td>\n",
       "      <td>-0.000548</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>-0.000880</td>\n",
       "      <td>-0.004274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.007229</td>\n",
       "      <td>-0.000855</td>\n",
       "      <td>0.004731</td>\n",
       "      <td>0.002393</td>\n",
       "      <td>0.000866</td>\n",
       "      <td>0.005405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.002552</td>\n",
       "      <td>-0.002653</td>\n",
       "      <td>-0.001393</td>\n",
       "      <td>-0.004763</td>\n",
       "      <td>-0.002223</td>\n",
       "      <td>0.002108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>-0.000942</td>\n",
       "      <td>-0.000141</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>0.004364</td>\n",
       "      <td>-0.001559</td>\n",
       "      <td>-0.002354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>-0.001236</td>\n",
       "      <td>0.000772</td>\n",
       "      <td>-0.001295</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>-0.002380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.004865</td>\n",
       "      <td>-0.002481</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>-0.003671</td>\n",
       "      <td>-0.002115</td>\n",
       "      <td>0.004781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.001744</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>-0.000713</td>\n",
       "      <td>-0.000451</td>\n",
       "      <td>0.000015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-0.001595</td>\n",
       "      <td>-0.005418</td>\n",
       "      <td>-0.005632</td>\n",
       "      <td>-0.005992</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>0.000961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.003901</td>\n",
       "      <td>-0.001541</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>-0.000070</td>\n",
       "      <td>0.000454</td>\n",
       "      <td>0.001570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.002666</td>\n",
       "      <td>0.001002</td>\n",
       "      <td>-0.001764</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.002506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>-0.001431</td>\n",
       "      <td>0.003692</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.004787</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>-0.000807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.001880</td>\n",
       "      <td>0.003155</td>\n",
       "      <td>0.000696</td>\n",
       "      <td>0.001867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.004554</td>\n",
       "      <td>-0.000559</td>\n",
       "      <td>-0.004107</td>\n",
       "      <td>-0.002591</td>\n",
       "      <td>0.000761</td>\n",
       "      <td>-0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.003460</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>0.002171</td>\n",
       "      <td>0.001417</td>\n",
       "      <td>-0.004293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>-0.000619</td>\n",
       "      <td>0.003101</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>-0.002303</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>-0.003458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.001851</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000477</td>\n",
       "      <td>0.002368</td>\n",
       "      <td>-0.003071</td>\n",
       "      <td>-0.000999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.002700</td>\n",
       "      <td>-0.002479</td>\n",
       "      <td>-0.003646</td>\n",
       "      <td>-0.006257</td>\n",
       "      <td>0.000918</td>\n",
       "      <td>-0.003540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-0.000291</td>\n",
       "      <td>-0.000455</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>-0.003830</td>\n",
       "      <td>-0.003464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.001825</td>\n",
       "      <td>0.001822</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>-0.002602</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>-0.003309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.001623</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>0.000724</td>\n",
       "      <td>0.001116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.001164</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.004190</td>\n",
       "      <td>-0.004959</td>\n",
       "      <td>0.000877</td>\n",
       "      <td>0.000616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.001920</td>\n",
       "      <td>-0.000944</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.000048</td>\n",
       "      <td>-0.003084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000992</td>\n",
       "      <td>-0.001960</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.003663</td>\n",
       "      <td>0.001693</td>\n",
       "      <td>0.004338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001429</td>\n",
       "      <td>-0.004409</td>\n",
       "      <td>0.001478</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.000582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.000725</td>\n",
       "      <td>0.003842</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>-0.000676</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.001691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.000799</td>\n",
       "      <td>-0.001326</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.001642</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.000170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.004027</td>\n",
       "      <td>-0.004331</td>\n",
       "      <td>-0.006731</td>\n",
       "      <td>-0.005068</td>\n",
       "      <td>0.001588</td>\n",
       "      <td>0.004228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.000391</td>\n",
       "      <td>0.002854</td>\n",
       "      <td>0.000950</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>-0.001650</td>\n",
       "      <td>-0.001488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-0.002817</td>\n",
       "      <td>0.000700</td>\n",
       "      <td>0.000289</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>0.000830</td>\n",
       "      <td>-0.000203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.002862</td>\n",
       "      <td>-0.001526</td>\n",
       "      <td>-0.004712</td>\n",
       "      <td>-0.004970</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-0.002665</td>\n",
       "      <td>0.000245</td>\n",
       "      <td>-0.001712</td>\n",
       "      <td>0.000616</td>\n",
       "      <td>-0.000973</td>\n",
       "      <td>-0.002312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.002084</td>\n",
       "      <td>-0.002388</td>\n",
       "      <td>-0.004907</td>\n",
       "      <td>-0.005956</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002359</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5\n",
       "17 -0.007368 -0.005240 -0.004246 -0.006304  0.000809  0.003532\n",
       "5  -0.005714 -0.006824  0.001335 -0.000417  0.000725 -0.000727\n",
       "33  0.003551  0.001367 -0.001101 -0.000361 -0.000557  0.003469\n",
       "48  0.002507  0.002694  0.002059  0.000290 -0.000156 -0.002088\n",
       "58  0.000668 -0.000813  0.006170  0.002906 -0.002476  0.000330\n",
       "2  -0.002759  0.001104  0.000341 -0.000792  0.003832 -0.000020\n",
       "36  0.000503 -0.005084 -0.002883  0.004016  0.001415 -0.000622\n",
       "54 -0.001155  0.004905  0.002991  0.005849 -0.001279  0.004633\n",
       "46 -0.002019  0.000097  0.001601 -0.000900 -0.001941 -0.004775\n",
       "51 -0.000868  0.004477  0.001178  0.001421  0.001766 -0.004702\n",
       "59  0.000076  0.006010  0.003136  0.001714  0.000501  0.003549\n",
       "35  0.006555  0.003974 -0.000240  0.003947 -0.002288  0.003274\n",
       "32  0.004159  0.001122 -0.004290  0.001681 -0.004668 -0.000230\n",
       "10  0.000330  0.003582  0.001613  0.000090 -0.002155 -0.000534\n",
       "56 -0.000092 -0.003041  0.002562  0.001773  0.001230  0.001610\n",
       "39  0.004409 -0.003615 -0.001977 -0.002797 -0.004215  0.003713\n",
       "8   0.004439 -0.003346 -0.002271 -0.001065 -0.003016  0.001821\n",
       "40  0.006360  0.001308  0.001281  0.003900 -0.000179  0.000545\n",
       "19 -0.001942 -0.004445 -0.003178 -0.003595 -0.001905  0.001898\n",
       "31 -0.000496 -0.000502 -0.002990  0.000607 -0.002641 -0.004012\n",
       "28 -0.005982 -0.001000  0.001675  0.004381 -0.002314 -0.003643\n",
       "49  0.004733  0.003294  0.000007  0.001061  0.000450 -0.003271\n",
       "30 -0.001233 -0.002927 -0.000548  0.005025 -0.000880 -0.004274\n",
       "38  0.007229 -0.000855  0.004731  0.002393  0.000866  0.005405\n",
       "18 -0.002552 -0.002653 -0.001393 -0.004763 -0.002223  0.002108\n",
       "29 -0.000942 -0.000141 -0.000144  0.004364 -0.001559 -0.002354\n",
       "43 -0.001236  0.000772 -0.001295  0.001017  0.000254 -0.002380\n",
       "34  0.004865 -0.002481  0.002688 -0.003671 -0.002115  0.004781\n",
       "0  -0.000315  0.001744  0.003533 -0.000713 -0.000451  0.000015\n",
       "20 -0.001595 -0.005418 -0.005632 -0.005992 -0.001541  0.000961\n",
       "37  0.003901 -0.001541  0.004760 -0.000070  0.000454  0.001570\n",
       "3  -0.002666  0.001002 -0.001764 -0.001878  0.000028  0.002506\n",
       "47 -0.001431  0.003692  0.001419  0.004787  0.001150 -0.000807\n",
       "57  0.002593  0.002543  0.001880  0.003155  0.000696  0.001867\n",
       "13 -0.004554 -0.000559 -0.004107 -0.002591  0.000761 -0.001037\n",
       "22  0.000690  0.003460  0.005854  0.002171  0.001417 -0.004293\n",
       "44 -0.000619  0.003101 -0.000039 -0.002303  0.002193 -0.003458\n",
       "24 -0.001851 -0.000102 -0.000477  0.002368 -0.003071 -0.000999\n",
       "21  0.002700 -0.002479 -0.003646 -0.006257  0.000918 -0.003540\n",
       "23 -0.000291 -0.000455  0.000136  0.005072 -0.003830 -0.003464\n",
       "45  0.001825  0.001822  0.001150 -0.002602  0.004379 -0.003309\n",
       "53  0.000480  0.001623  0.002799  0.000229  0.000724  0.001116\n",
       "9   0.001164  0.003651  0.004190 -0.004959  0.000877  0.000616\n",
       "50  0.001920 -0.000944  0.000389 -0.000310  0.000048 -0.003084\n",
       "7   0.000992 -0.001960  0.002031  0.003663  0.001693  0.004338\n",
       "1  -0.001429 -0.004409  0.001478  0.002118  0.002338  0.000582\n",
       "55  0.000725  0.003842  0.002240 -0.000676  0.000075  0.001691\n",
       "6  -0.000799 -0.001326  0.001843  0.001642  0.003897  0.000170\n",
       "11 -0.004027 -0.004331 -0.006731 -0.005068  0.001588  0.004228\n",
       "52  0.000391  0.002854  0.000950  0.005164 -0.001650 -0.001488\n",
       "27 -0.002817  0.000700  0.000289 -0.001517  0.000830 -0.000203\n",
       "14 -0.002862 -0.001526 -0.004712 -0.004970  0.003152  0.001373\n",
       "25 -0.002665  0.000245 -0.001712  0.000616 -0.000973 -0.002312\n",
       "15 -0.002084 -0.002388 -0.004907 -0.005956  0.002342  0.002359"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, y, W):\n",
    "    \"\"\"\n",
    "    compute the gradient\n",
    "    :param X: data matrix (train) \n",
    "    :param y: the corresponding \n",
    "    :param W: weight matrix\n",
    "    :return: Jacobian dW with all gradients\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape)\n",
    "    \n",
    "    for index, x in enumerate(X.as_matrix()):\n",
    "        y_index = y[index].argmax()\n",
    "        y_value = x.dot(W)[y_index]\n",
    "        y_hat_max_value = np.delete(x.dot(W), y_index).max()\n",
    "        loss = max(0, 1 - (y_value - y_hat_max_value))\n",
    "        y_hat_max_index = np.delete(x.dot(W), y_index).argmax() + 1\n",
    "        dW[:, y_hat_max_index] += x.transpose()\n",
    "        dW[:, y_index] -= x.transpose()\n",
    "            \n",
    "    return dW\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, W, eta, steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for a number of times with a fixed learning rate eta\n",
    "    :param X: data matrix\n",
    "    :param y: labels\n",
    "    :param W: weight matrix\n",
    "    :param eta: learning rate\n",
    "    :param steps: number of times gradient descent should be performed\n",
    "    :return: learned representation matrix W_learned\n",
    "    \"\"\"\n",
    "    W_learned = W.copy()\n",
    "    \n",
    "    for step in range(0, steps):\n",
    "        dW = gradient(X, y, W)\n",
    "        W_learned = W_learned - eta * dW\n",
    "        \n",
    "    return W_learned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_star = gradient_descent(X_train, y_train, W, eta=0.001, steps=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing\n",
    "Let's test if our learned representation of the data is any good at classifying the data in the test set. Of course we need the bias in our test set as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_vector_test = np.ones([X_test.shape[0], 1])\n",
    "X_test['bias'] = bias_vector_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "3 3\n",
      "3 3\n",
      "5 4\n",
      "0 0\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_test.dot(W_star).as_matrix()):\n",
    "    pred = x.argmax()\n",
    "    true_label = y_test[index].argmax()\n",
    "    print(pred, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too bad! But Goldberg mentioned something about regularisation, so we should take this into account as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_reg(X, y, W, lam):\n",
    "    \"\"\"\n",
    "    compute the gradient\n",
    "    :param X: data matrix (train) \n",
    "    :param y: the corresponding \n",
    "    :param W: weight matrix\n",
    "    :param lam: reguliser lambda\n",
    "    :return: Jacobian dW with all gradients\n",
    "    \"\"\"\n",
    "    dW = np.zeros(W.shape)\n",
    "    \n",
    "    for index, x in enumerate(X.as_matrix()):\n",
    "        y_index = y[index].argmax()\n",
    "        y_value = x.dot(W)[y_index]\n",
    "        y_hat_max_value = np.delete(x.dot(W), y_index).max()\n",
    "        loss = max(0, 1 - (y_value - y_hat_max_value)) + lam * np.linalg.norm(W, 2)\n",
    "        y_hat_max_index = np.delete(x.dot(W), y_index).argmax() + 1\n",
    "        dW[:, y_hat_max_index] += x.transpose()\n",
    "        dW[:, y_index] -= x.transpose()\n",
    "        \n",
    "    dW += 2 * lam * W\n",
    "            \n",
    "    return dW\n",
    "\n",
    "def gradient_descent_reg(X, y, W, eta, steps):\n",
    "    \"\"\"\n",
    "    Perform gradient descent for a number of times with a fixed learning rate eta\n",
    "    :param X: data matrix\n",
    "    :param y: labels\n",
    "    :param W: weight matrix\n",
    "    :param eta: learning rate\n",
    "    :param steps: number of times gradient descent should be performed\n",
    "    :return: learned representation matrix W_learned\n",
    "    \"\"\"\n",
    "    W_learned = W.copy()\n",
    "    \n",
    "    for step in range(0, steps):\n",
    "        dW = gradient_reg(X, y, W, 10000)\n",
    "        W_learned = W_learned - eta * dW\n",
    "        \n",
    "    return W_learned\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_star_reg = gradient_descent_reg(X_train, y_train, W, eta=0.001, steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1\n",
      "3 3\n",
      "3 3\n",
      "5 4\n",
      "0 0\n",
      "5 5\n"
     ]
    }
   ],
   "source": [
    "for index, x in enumerate(X_test.dot(W_star_reg).as_matrix()):\n",
    "    pred = x.argmax()\n",
    "    true_label = y_test[index].argmax()\n",
    "    print(pred, true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we look at the two different weight matrices (one regularised, the other not), we notice the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -3.62884341,   6.65219608,  -2.86095923,   9.6367692 ,\n",
       "         -5.0512049 ,  -4.74783246],\n",
       "       [ -8.29494248,   4.55412785,  -8.44787706,   1.96171449,\n",
       "          5.50408688,   4.72306357],\n",
       "       [ -7.44999196,  -5.28210705,   7.14396926,  -9.96290448,\n",
       "          5.68291142,   9.86846259],\n",
       "       [ 15.8677606 ,  -4.57988938,   0.8284553 ,  -5.34201712,\n",
       "          3.88057968, -10.65499262],\n",
       "       [ -0.66189841,  -4.25884237,   2.70457813,  -9.6260341 ,\n",
       "          8.27210477,   3.57016276]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-7.26946916e-01,  2.83028982e+00, -4.28471754e+00,\n",
       "         1.01322458e+01, -5.77413737e+00, -4.68193312e+00],\n",
       "       [-7.85224904e+00,  3.59961430e+00, -7.06399831e+00,\n",
       "         3.77702627e-01,  5.35758862e+00,  2.11649150e+00],\n",
       "       [-7.87695494e+00, -7.31680495e+00,  3.32054570e+00,\n",
       "        -8.90356121e+00,  1.99864110e+00,  1.19829328e+01],\n",
       "       [ 1.75935932e+01, -5.05515238e+00,  3.13681884e+00,\n",
       "        -7.77198520e+00,  6.46809785e+00, -1.23004382e+01],\n",
       "       [ 2.40384248e-03, -1.69598435e+00,  2.26750250e+00,\n",
       "        -1.37929826e+01,  8.76854089e+00,  3.03524196e+00]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W_star_reg[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By the way ...\n",
    "### In scikit-learn it's much easier to implement this :-)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='hinge', max_iter=1000,\n",
       "     multi_class='crammer_singer', penalty='l2', random_state=0,\n",
       "     tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "clf = LinearSVC(random_state=0, multi_class='crammer_singer', loss='hinge')\n",
    "clf.fit(X_train, train.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['en', 'fi', 'fi', 'fr', 'de', 'it'], dtype=object)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4     en\n",
       "12    fi\n",
       "16    fi\n",
       "26    fr\n",
       "41    de\n",
       "42    it\n",
       "Name: y, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that with our naive implementation, we do not much worse than with scikit's. scikit's implementation is of course much more elaborate and uses the vectorised operation and possibly other optimisation techniques in order to make its SVM (or SVC) better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
